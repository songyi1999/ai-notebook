---
description: 容器化和部署集成参考
globs: 
alwaysApply: false
---
# Docker部署指导

## 容器化架构

### 服务组成

根据 [README.md](mdc:README.md) 和 [开发计划.md](mdc:开发计划.md) 的架构设计，系统包含2个核心Docker服务 + 外部AI服务：

1. **frontend** - React前端应用
2. **backend** - FastAPI + SQLite + ChromaDB
3. **外部Ollama服务** - 在宿主机运行的AI模型服务

## Docker Compose配置

### 主配置文件（实际使用的配置）

```yaml
# docker-compose.yml
version: '3.8'

name: ai-notebook

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:8000
    depends_on:
      - backend
    networks:
      - ai-notebook-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - APP_NAME=AI笔记本
      - APP_VERSION=1.0.0
      - DEBUG_MODE=false
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8000
      - DATABASE_URL=sqlite:///./data/ai_notebook.db
      - CHROMA_DB_PATH=./data/chroma_db
      - OPENAI_API_KEY=ollama
      - OPENAI_BASE_URL=http://host.docker.internal:11434
      - EMBEDDING_MODEL_NAME=quentinz/bge-large-zh-v1.5:latest 
      - OPENAI_MODEL=qwen2.5:0.5b
      - LLM_TEMPERATURE=0.7
      - LLM_MAX_TOKENS=2048
      - EMBEDDING_DIMENSION=1024
      - MAX_FILE_SIZE=10485760
      - SEARCH_CHUNK_SIZE=1000
      - SEARCH_OVERLAP=200
    volumes:
      - ./backend/data:/app/data
      - ./notes:/app/notes
    networks:
      - ai-notebook-network

networks:
  ai-notebook-network:
    driver: bridge 
```

### 开发环境配置

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:8000
      - NODE_ENV=development

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8000"
    volumes:
      - ./backend/app:/app/app
      - ./data:/app/data
    environment:
      - DEBUG_MODE=true
      - RELOAD=true
```

### 外部Ollama服务要求

项目需要在宿主机上运行Ollama服务：

```bash
# 安装并启动Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve

# 下载所需模型
ollama pull qwen2.5:0.5b
ollama pull quentinz/bge-large-zh-v1.5:latest
```

## Dockerfile配置

### 前端Dockerfile

```dockerfile
# frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# 复制package文件
COPY package*.json ./
RUN npm ci --only=production

# 复制源码并构建
COPY . .
RUN npm run build

# 生产环境
FROM nginx:alpine

# 复制构建产物
COPY --from=builder /app/dist /usr/share/nginx/html

# 复制nginx配置
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 3000

CMD ["nginx", "-g", "daemon off;"]
```

```dockerfile
# frontend/Dockerfile.dev
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 3000

CMD ["npm", "run", "dev"]
```

### 后端Dockerfile

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 创建数据目录
RUN mkdir -p /app/data/notes /app/data/chroma_db

# 设置权限
RUN chmod +x /app/scripts/start.sh

EXPOSE 8000

CMD ["./scripts/start.sh"]
```

```dockerfile
# backend/Dockerfile.dev
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && apt-get install -y gcc g++

COPY requirements.txt .
COPY requirements-dev.txt .
RUN pip install -r requirements-dev.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

## 启动脚本

### 生产环境启动

```bash
#!/bin/bash
# scripts/start-prod.sh

echo "启动AI笔记本项目..."

# 检查Docker和Docker Compose
if ! command -v docker &> /dev/null; then
    echo "错误: 请先安装Docker"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "错误: 请先安装Docker Compose"
    exit 1
fi

# 创建数据目录
mkdir -p ./data/notes ./data/chroma_db

# 设置权限
chmod 755 ./data

# 启动服务
echo "启动容器服务..."
docker-compose up -d

# 等待服务启动
echo "等待服务启动..."
sleep 10

# 检查服务状态
echo "检查服务状态..."
docker-compose ps

# 初始化Ollama模型
echo "初始化AI模型..."
./scripts/init-models.sh

echo "启动完成！"
echo "前端访问地址: http://localhost:3000"
echo "后端API地址: http://localhost:8000"
echo "API文档地址: http://localhost:8000/docs"
```

### 开发环境启动

```bash
#!/bin/bash
# scripts/start-dev.sh

echo "启动开发环境..."

# 启动开发容器
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d

echo "开发环境启动完成！"
echo "前端开发服务器: http://localhost:3000"
echo "后端开发服务器: http://localhost:8000"
echo "热重载已启用"
```

### 模型初始化脚本

```bash
#!/bin/bash
# scripts/init-models.sh

echo "初始化Ollama模型..."

# 等待Ollama服务启动
until curl -f http://localhost:11434/api/tags; do
    echo "等待Ollama服务启动..."
    sleep 5
done

# 下载LLM模型
echo "下载LLM模型..."
docker exec ai-notebook-ollama-1 ollama pull llama3.2:latest

# 下载嵌入模型
echo "下载嵌入模型..."
docker exec ai-notebook-ollama-1 ollama pull bge-m3:latest

echo "模型初始化完成！"
```

## 环境配置

### 环境变量文件

```bash
# .env
# 应用配置
APP_NAME=AI笔记本
APP_VERSION=1.0.0
DEBUG_MODE=false

# 服务器配置
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# 数据库配置
DATABASE_URL=sqlite:///./data/notebook.db
CHROMA_DB_PATH=./data/chroma_db

# AI模型配置
OLLAMA_API_URL=http://ollama:11434
OLLAMA_API_KEY=ollama
LLM_MODEL_NAME=llama3.2:latest
EMBEDDING_MODEL_NAME=bge-m3:latest

# 文件存储配置
NOTES_ROOT_PATH=./data/notes
MAX_FILE_SIZE=10485760

# 搜索配置
SEARCH_CHUNK_SIZE=1000
SEARCH_OVERLAP=200
```

```bash
# .env.dev
# 开发环境配置
DEBUG_MODE=true
RELOAD=true

# 前端配置
REACT_APP_API_BASE_URL=http://localhost:8000
NODE_ENV=development
```

## 数据持久化

### 数据卷管理

```bash
# 数据目录结构
./data/
├── notebook.db          # SQLite数据库
├── chroma_db/           # ChromaDB向量数据库
└── notes/               # Markdown文件存储
    ├── 技术/
    ├── 生活/
    └── 工作/
```

### 备份脚本

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "创建备份: $BACKUP_DIR"

# 备份数据库
cp ./data/notebook.db "$BACKUP_DIR/"

# 备份向量数据库
cp -r ./data/chroma_db "$BACKUP_DIR/"

# 备份笔记文件
cp -r ./data/notes "$BACKUP_DIR/"

# 创建压缩包
tar -czf "$BACKUP_DIR.tar.gz" -C "$BACKUP_DIR" .

echo "备份完成: $BACKUP_DIR.tar.gz"
```

### 恢复脚本

```bash
#!/bin/bash
# scripts/restore.sh

if [ -z "$1" ]; then
    echo "用法: ./restore.sh <备份文件.tar.gz>"
    exit 1
fi

BACKUP_FILE="$1"
TEMP_DIR="/tmp/restore_$(date +%s)"

echo "从备份恢复: $BACKUP_FILE"

# 停止服务
docker-compose down

# 解压备份
mkdir -p "$TEMP_DIR"
tar -xzf "$BACKUP_FILE" -C "$TEMP_DIR"

# 恢复数据
cp "$TEMP_DIR/notebook.db" ./data/
cp -r "$TEMP_DIR/chroma_db" ./data/
cp -r "$TEMP_DIR/notes" ./data/

# 清理临时文件
rm -rf "$TEMP_DIR"

# 重启服务
docker-compose up -d

echo "恢复完成！"
```

## 监控和日志

### 日志配置

```yaml
# 添加到docker-compose.yml
services:
  backend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  
  frontend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

### 健康检查

```bash
#!/bin/bash
# scripts/health-check.sh

echo "检查服务健康状态..."

# 检查前端服务
if curl -f http://localhost:3000 > /dev/null 2>&1; then
    echo "✓ 前端服务正常"
else
    echo "✗ 前端服务异常"
fi

# 检查后端服务
if curl -f http://localhost:8000/health > /dev/null 2>&1; then
    echo "✓ 后端服务正常"
else
    echo "✗ 后端服务异常"
fi

# 检查Ollama服务
if curl -f http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "✓ Ollama服务正常"
else
    echo "✗ Ollama服务异常"
fi
```

## 部署最佳实践

### 资源配置

```yaml
# 生产环境资源限制
services:
  backend:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
  
  ollama:
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
```

### 安全配置

```yaml
# 网络安全
networks:
  ai-notebook-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

### 更新策略

```bash
#!/bin/bash
# scripts/update.sh

echo "更新AI笔记本项目..."

# 拉取最新代码
git pull origin main

# 重新构建镜像
docker-compose build --no-cache

# 滚动更新
docker-compose up -d --force-recreate

echo "更新完成！"
```

参考 [开发计划.md](mdc:开发计划.md) 了解完整的部署架构和技术选型。

