---
description: 后端开发参考，
globs: 
alwaysApply: false
---
# 后端开发指导

## 技术栈

### 核心技术
- **框架**：FastAPI + Python 3.9+
- **数据库**：SQLite + ChromaDB
- **ORM**：SQLAlchemy 2.0
- **AI集成**：Ollama (OpenAI兼容接口)
- **异步处理**：asyncio + BackgroundTasks
- **API文档**：Swagger/OpenAPI自动生成

### 开发工具
- **代码规范**：Black + isort + flake8
- **类型检查**：mypy
- **测试**：pytest + httpx
- **依赖管理**：pip + requirements.txt

## 项目结构

```
backend/
├── app/
│   ├── api/                 # API路由
│   │   ├── files.py        # 文件管理API
│   │   ├── search.py       # 搜索API
│   │   ├── chat.py         # AI问答API
│   │   └── graph.py        # 链接图谱API
│   ├── core/               # 核心配置
│   │   ├── config.py       # 配置管理
│   │   ├── database.py     # 数据库连接
│   │   └── security.py     # 安全配置
│   ├── models/             # 数据模型
│   │   ├── file.py         # 文件模型
│   │   ├── search.py       # 搜索模型
│   │   └── chat.py         # 对话模型
│   ├── services/           # 业务逻辑
│   │   ├── file_service.py # 文件服务
│   │   ├── search_service.py # 搜索服务
│   │   ├── ai_service.py   # AI服务
│   │   └── embedding_service.py # 嵌入服务
│   ├── schemas/            # Pydantic模式
│   └── utils/              # 工具函数
├── tests/                  # 测试文件
├── requirements.txt        # 依赖列表
└── main.py                # 应用入口
```

## 核心模块设计

### 1. 配置管理

参考 [README.md](mdc:README.md) 中的环境变量配置。

```python
# app/core/config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # 应用配置
    APP_NAME: str = "AI笔记本"
    APP_VERSION: str = "1.0.0"
    DEBUG_MODE: bool = False
    
    # 服务器配置
    SERVER_HOST: str = "0.0.0.0"
    SERVER_PORT: int = 8000
    
    # 数据库配置
    DATABASE_URL: str = "sqlite:///./notebook.db"
    CHROMA_DB_PATH: str = "./chroma_db"
    
    # AI模型配置
    OPENAI_BASE_URL: str = "http://host.docker.internal:11434"
    OPENAI_API_KEY: str = "ollama"
    OPENAI_MODEL: str = "qwen2.5:0.5b"
    EMBEDDING_MODEL_NAME: str = "quentinz/bge-large-zh-v1.5:latest"
    LLM_TEMPERATURE: float = 0.7
    LLM_MAX_TOKENS: int = 2048
    EMBEDDING_DIMENSION: int = 1024
    
    # 文件存储配置
    NOTES_DIRECTORY: str = "../notes"
    MAX_FILE_SIZE: int = 10 * 1024 * 1024  # 10MB
    
    class Config:
        env_file = ".env"

settings = Settings()
```

### 2. 数据库模型

参考 [DATABASE.md](mdc:DATABASE.md) 的完整数据库设计。

```python
# app/models/file.py
from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

class File(Base):
    __tablename__ = "files"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    file_path = Column(String, unique=True, nullable=False)
    title = Column(String, nullable=False)
    content = Column(Text)
    content_hash = Column(String)
    file_size = Column(Integer, default=0)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    is_deleted = Column(Boolean, default=False)
    parent_folder = Column(String)
    tags = Column(Text)  # JSON格式
    metadata = Column(Text)  # JSON格式
```

### 3. API路由设计

```python
# app/api/files.py
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from app.services.file_service import FileService
from app.schemas.file import FileResponse, FileCreate, FileUpdate

router = APIRouter(prefix="/files", tags=["files"])

@router.get("/", response_model=List[FileResponse])
async def get_files(file_service: FileService = Depends()):
    """获取所有文件列表"""
    return await file_service.get_all_files()

@router.get("/{file_path:path}", response_model=FileResponse)
async def get_file(file_path: str, file_service: FileService = Depends()):
    """获取单个文件内容"""
    file = await file_service.get_file_by_path(file_path)
    if not file:
        raise HTTPException(status_code=404, detail="文件不存在")
    return file

@router.put("/{file_path:path}")
async def update_file(
    file_path: str, 
    file_update: FileUpdate,
    background_tasks: BackgroundTasks,
    file_service: FileService = Depends()
):
    """更新文件内容"""
    # 同步保存
    file = await file_service.update_file(file_path, file_update.content)
    
    # 异步更新索引
    background_tasks.add_task(
        file_service.update_file_index, 
        file.id, 
        file_update.content
    )
    
    return {"message": "文件保存成功"}
```

### 4. 业务服务层

```python
# app/services/file_service.py
from app.models.file import File
from app.core.database import get_db
from app.services.embedding_service import EmbeddingService
import hashlib
import os

class FileService:
    def __init__(self, db_session, embedding_service: EmbeddingService):
        self.db = db_session
        self.embedding_service = embedding_service
    
    async def get_all_files(self) -> List[File]:
        """获取所有文件"""
        return self.db.query(File).filter(File.is_deleted == False).all()
    
    async def get_file_by_path(self, file_path: str) -> File:
        """根据路径获取文件"""
        return self.db.query(File).filter(
            File.file_path == file_path,
            File.is_deleted == False
        ).first()
    
    async def update_file(self, file_path: str, content: str) -> File:
        """更新文件内容（同步操作）"""
        # 1. 计算内容哈希
        content_hash = hashlib.sha256(content.encode()).hexdigest()
        
        # 2. 更新数据库
        file = await self.get_file_by_path(file_path)
        if file:
            file.content = content
            file.content_hash = content_hash
            file.file_size = len(content.encode())
        else:
            file = File(
                file_path=file_path,
                title=self._extract_title(content),
                content=content,
                content_hash=content_hash,
                file_size=len(content.encode())
            )
            self.db.add(file)
        
        # 3. 保存到文件系统
        await self._save_to_filesystem(file_path, content)
        
        self.db.commit()
        return file
    
    async def update_file_index(self, file_id: int, content: str):
        """更新文件索引（异步操作）"""
        # 1. 删除旧的嵌入向量
        await self.embedding_service.delete_embeddings(file_id)
        
        # 2. 重新生成嵌入向量
        await self.embedding_service.create_embeddings(file_id, content)
        
        # 3. 更新链接索引
        await self._update_links(file_id, content)
        
        # 4. 更新标签
        await self._update_tags(file_id, content)
```

### 5. AI服务集成

```python
# app/services/ai_service.py
import openai
from app.core.config import settings
from app.services.search_service import SearchService

class AIService:
    def __init__(self, search_service: SearchService):
        self.client = openai.OpenAI(
            base_url=f"{settings.OLLAMA_API_URL}/v1",
            api_key=settings.OLLAMA_API_KEY
        )
        self.search_service = search_service
    
    async def chat_completion(self, message: str, session_id: str) -> str:
        """AI问答"""
        # 1. 检索相关文档
        relevant_docs = await self.search_service.semantic_search(
            query=message, 
            limit=5
        )
        
        # 2. 构建上下文
        context = self._build_context(relevant_docs)
        
        # 3. 构建提示
        prompt = self._build_prompt(message, context)
        
        # 4. 调用LLM
        response = self.client.chat.completions.create(
            model=settings.LLM_MODEL_NAME,
            messages=[
                {"role": "system", "content": "你是一个智能助手"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2048
        )
        
        return response.choices[0].message.content
    
    def _build_context(self, docs: List[dict]) -> str:
        """构建上下文"""
        context_parts = []
        for doc in docs:
            context_parts.append(f"文档：{doc['file_path']}\n内容：{doc['content']}")
        return "\n\n".join(context_parts)
    
    def _build_prompt(self, message: str, context: str) -> str:
        """构建提示"""
        return f"""基于以下上下文回答问题：

{context}

问题：{message}

请基于上下文提供准确的答案，如果上下文中没有相关信息，请明确说明。"""
```

## 数据库操作

### SQLAlchemy配置

```python
# app/core/database.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.core.config import settings

engine = create_engine(
    settings.DATABASE_URL,
    echo=settings.DEBUG_MODE,
    pool_pre_ping=True
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

### FTS5全文搜索

```python
# app/services/search_service.py
from sqlalchemy import text

class SearchService:
    def __init__(self, db_session):
        self.db = db_session
    
    async def keyword_search(self, query: str, limit: int = 10):
        """FTS5关键词搜索"""
        sql = text("""
            SELECT f.id, f.file_path, f.title, f.content,
                   snippet(files_fts, 2, '<mark>', '</mark>', '...', 50) as snippet,
                   rank as score
            FROM files_fts 
            JOIN files f ON files_fts.rowid = f.id
            WHERE files_fts MATCH :query
            AND f.is_deleted = 0
            ORDER BY rank
            LIMIT :limit
        """)
        
        result = self.db.execute(sql, {"query": query, "limit": limit})
        return result.fetchall()
    
    async def mixed_search(self, query: str, limit: int = 10):
        """混合搜索：FTS5 + ChromaDB"""
        # 1. FTS5搜索
        keyword_results = await self.keyword_search(query, limit // 2)
        
        # 2. 语义搜索
        semantic_results = await self.semantic_search(query, limit // 2)
        
        # 3. 结果融合和排序
        return self._merge_results(keyword_results, semantic_results)
```

## 性能优化

### 异步处理

```python
# 使用BackgroundTasks处理耗时操作
from fastapi import BackgroundTasks

@router.put("/files/{file_path}")
async def update_file(
    file_path: str,
    content: str,
    background_tasks: BackgroundTasks
):
    # 同步保存文件
    file = await file_service.save_file(file_path, content)
    
    # 异步更新索引
    background_tasks.add_task(
        update_file_embeddings,
        file.id,
        content
    )
    
    return {"message": "保存成功"}
```

### 缓存策略

```python
# app/utils/cache.py
from functools import lru_cache
import asyncio

class AsyncLRUCache:
    def __init__(self, maxsize=128):
        self.cache = {}
        self.maxsize = maxsize
    
    def get(self, key):
        return self.cache.get(key)
    
    def set(self, key, value):
        if len(self.cache) >= self.maxsize:
            # 删除最旧的条目
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        self.cache[key] = value

# 使用缓存
embedding_cache = AsyncLRUCache(maxsize=1000)
```

## 错误处理

```python
# app/core/exceptions.py
from fastapi import HTTPException

class FileNotFoundError(HTTPException):
    def __init__(self, file_path: str):
        super().__init__(
            status_code=404,
            detail=f"文件不存在: {file_path}"
        )

class AIServiceError(HTTPException):
    def __init__(self, message: str):
        super().__init__(
            status_code=503,
            detail=f"AI服务错误: {message}"
        )
```

## 测试策略

```python
# tests/test_file_api.py
import pytest
from httpx import AsyncClient
from app.main import app

@pytest.mark.asyncio
async def test_get_files():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        response = await ac.get("/files/")
    assert response.status_code == 200

@pytest.mark.asyncio
async def test_update_file():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        response = await ac.put(
            "/files/test.md",
            json={"content": "# 测试文档\n\n这是测试内容"}
        )
    assert response.status_code == 200
```

参考 [DATABASE.md](mdc:DATABASE.md) 了解完整的数据库结构设计。

