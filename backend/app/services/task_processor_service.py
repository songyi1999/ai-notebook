import os
import time
import logging
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, text
from pathlib import Path

from ..models.pending_task import PendingTask
from ..models.file import File
from ..database.session import get_db
from .ai_service_langchain import AIService
from .index_service import IndexService

logger = logging.getLogger(__name__)

# æ·»åŠ ä»»åŠ¡ç»Ÿè®¡ç¼“å­˜
_task_stats_cache = {
    "data": None,
    "last_update": None,
    "cache_duration": 15  # ç¼“å­˜15ç§’
}

class TaskProcessorService:
    """åå°ä»»åŠ¡å¤„ç†æœåŠ¡"""
    
    def __init__(self, db: Session):
        self.db = db
        self.lock_file = Path("data/task_processor.lock")
        self.is_running = False
        
        # ä¸åœ¨åˆå§‹åŒ–æ—¶è‡ªåŠ¨æ¸…ç†é”æ–‡ä»¶ï¼Œé¿å…è¯¯æ¸…ç†æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å¤„ç†å™¨
    
    def _cleanup_stale_lock_on_startup(self):
        """
        å®¹å™¨å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸçš„é”æ–‡ä»¶
        
        åœ¨Dockerå®¹å™¨ä¸­ï¼Œä¸Šæ¬¡è¿è¡Œçš„é”æ–‡ä»¶å¯èƒ½ä¼šå› ä¸ºå·æŒ‚è½½è€ŒæŒä¹…åŒ–ï¼Œ
        ä½†é”æ–‡ä»¶ä¸­çš„PIDåœ¨æ–°å®¹å™¨ä¸­å¯èƒ½è¢«å…¶ä»–è¿›ç¨‹å ç”¨ï¼Œå¯¼è‡´è¯¯åˆ¤ã€‚
        å› æ­¤åœ¨å¯åŠ¨æ—¶åº”è¯¥æ¸…ç†è¿‡æœŸçš„é”æ–‡ä»¶ã€‚
        """
        try:
            if self.lock_file.exists():
                # è¯»å–é”æ–‡ä»¶ä¸­çš„PID
                try:
                    lock_pid = int(self.lock_file.read_text().strip())
                    
                    # åœ¨Dockerå®¹å™¨å¯åŠ¨åœºæ™¯ä¸‹ï¼Œä»»ä½•ç°æœ‰çš„é”æ–‡ä»¶éƒ½åº”è¯¥è¢«æ¸…ç†
                    # å› ä¸ºçœŸæ­£çš„ä»»åŠ¡å¤„ç†å™¨è¿›ç¨‹ä¸ä¼šåœ¨å®¹å™¨å¯åŠ¨æ—¶å°±å­˜åœ¨
                    logger.info(f"å®¹å™¨å¯åŠ¨æ—¶å‘ç°è¿‡æœŸé”æ–‡ä»¶(PID: {lock_pid})ï¼Œæ¸…ç†ä¸­...")
                    self.lock_file.unlink()
                    logger.info("è¿‡æœŸé”æ–‡ä»¶å·²æ¸…ç†")
                    
                except (ValueError, IOError) as e:
                    logger.warning(f"é”æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œæ¸…ç†ä¸­: {e}")
                    self.lock_file.unlink()
                    logger.info("æ ¼å¼é”™è¯¯çš„é”æ–‡ä»¶å·²æ¸…ç†")
                    
        except Exception as e:
            logger.error(f"æ¸…ç†å¯åŠ¨é”æ–‡ä»¶å¤±è´¥: {e}")
        
    def _acquire_lock(self) -> bool:
        """è·å–å¤„ç†é”ï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œ"""
        try:
            if self.lock_file.exists():
                # è¯»å–é”æ–‡ä»¶ä¸­çš„PID
                try:
                    lock_pid = int(self.lock_file.read_text().strip())
                    
                    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                    if self._is_process_running(lock_pid):
                        logger.info(f"ä»»åŠ¡å¤„ç†å™¨å·²åœ¨è¿è¡Œä¸­(PID: {lock_pid})ï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ")
                        return False
                    else:
                        logger.warning(f"å‘ç°æ­»é”æ–‡ä»¶(PID: {lock_pid}å·²é€€å‡º)ï¼Œæ¸…ç†å¹¶ç»§ç»­æ‰§è¡Œ")
                        self.lock_file.unlink()
                except (ValueError, IOError) as e:
                    logger.warning(f"é”æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œæ¸…ç†å¹¶ç»§ç»­: {e}")
                    self.lock_file.unlink()
            
            # åˆ›å»ºé”æ–‡ä»¶
            self.lock_file.parent.mkdir(parents=True, exist_ok=True)
            current_pid = os.getpid()
            self.lock_file.write_text(str(current_pid))
            logger.info(f"è·å–ä»»åŠ¡å¤„ç†é”æˆåŠŸ(PID: {current_pid})")
            return True
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å¤„ç†é”å¤±è´¥: {e}")
            return False
    
    def _is_task_processor_running(self, pid: int) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šPIDæ˜¯å¦æ˜¯æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å¤„ç†å™¨è¿›ç¨‹
        
        æ”¹è¿›çš„æ£€æŸ¥é€»è¾‘ï¼š
        1. æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
        2. æ£€æŸ¥è¿›ç¨‹æ˜¯å¦æ˜¯Pythonè¿›ç¨‹
        3. æ£€æŸ¥è¿›ç¨‹å‘½ä»¤è¡Œæ˜¯å¦åŒ…å«ä»»åŠ¡å¤„ç†å™¨ç›¸å…³ä¿¡æ¯
        """
        try:
            import psutil
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
            if not psutil.pid_exists(pid):
                return False
            
            # è·å–è¿›ç¨‹ä¿¡æ¯
            try:
                process = psutil.Process(pid)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯Pythonè¿›ç¨‹
                if 'python' not in process.name().lower():
                    logger.debug(f"PID {pid} ä¸æ˜¯Pythonè¿›ç¨‹: {process.name()}")
                    return False
                
                # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°ï¼Œçœ‹æ˜¯å¦åŒ…å«ä»»åŠ¡å¤„ç†å™¨ç›¸å…³ä¿¡æ¯
                cmdline = ' '.join(process.cmdline())
                if 'task_processor' in cmdline.lower() or 'TaskProcessorService' in cmdline:
                    logger.debug(f"PID {pid} ç¡®å®æ˜¯ä»»åŠ¡å¤„ç†å™¨è¿›ç¨‹")
                    return True
                else:
                    logger.debug(f"PID {pid} æ˜¯Pythonè¿›ç¨‹ä½†ä¸æ˜¯ä»»åŠ¡å¤„ç†å™¨: {cmdline}")
                    return False
                    
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                return False
                
        except ImportError:
            # å¦‚æœæ²¡æœ‰psutilï¼Œä½¿ç”¨ä¿å®ˆçš„æ£€æŸ¥æ–¹å¼
            try:
                import signal
                # å‘é€0ä¿¡å·æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
                os.kill(pid, 0)
                # åœ¨æ²¡æœ‰psutilçš„æƒ…å†µä¸‹ï¼Œå‡è®¾è¿›ç¨‹å­˜åœ¨ä½†ä¸ç¡®å®šæ˜¯å¦æ˜¯ä»»åŠ¡å¤„ç†å™¨
                # ä¸ºäº†é¿å…è¯¯åˆ¤ï¼Œè¿”å›Falseï¼Œè®©é”æ–‡ä»¶è¢«æ¸…ç†
                logger.debug(f"æ— æ³•ç¡®å®šPID {pid} æ˜¯å¦æ˜¯ä»»åŠ¡å¤„ç†å™¨ï¼Œæ¸…ç†é”æ–‡ä»¶")
                return False
            except (OSError, ProcessLookupError):
                return False
        except Exception as e:
            # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œä¸ºäº†å®‰å…¨èµ·è§æ¸…ç†é”æ–‡ä»¶
            logger.debug(f"æ£€æŸ¥ä»»åŠ¡å¤„ç†å™¨è¿›ç¨‹å¤±è´¥: {e}ï¼Œæ¸…ç†é”æ–‡ä»¶")
            return False
    
    def _is_process_running(self, pid: int) -> bool:
        """æ£€æŸ¥è¿›ç¨‹æ˜¯å¦æ­£åœ¨è¿è¡Œï¼ˆä¿ç•™åŸæ–¹æ³•ä»¥å…¼å®¹å…¶ä»–åœ°æ–¹çš„è°ƒç”¨ï¼‰"""
        try:
            import psutil
            return psutil.pid_exists(pid)
        except ImportError:
            # å¦‚æœæ²¡æœ‰psutilï¼Œä½¿ç”¨ç³»ç»Ÿæ–¹æ³•æ£€æŸ¥
            try:
                import signal
                # å‘é€0ä¿¡å·æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
                os.kill(pid, 0)
                return True
            except (OSError, ProcessLookupError):
                return False
        except Exception:
            # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œä¸ºäº†å®‰å…¨èµ·è§å‡è®¾è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
            return True
    
    def _release_lock(self):
        """é‡Šæ”¾å¤„ç†é”"""
        try:
            if self.lock_file.exists():
                self.lock_file.unlink()
                logger.info("é‡Šæ”¾ä»»åŠ¡å¤„ç†é”æˆåŠŸ")
        except Exception as e:
            logger.error(f"é‡Šæ”¾ä»»åŠ¡å¤„ç†é”å¤±è´¥: {e}")
    
    def create_pending_task(self, file_id: int, task_type: str, priority: int = 1) -> bool:
        """åˆ›å»ºå¾…å¤„ç†ä»»åŠ¡ï¼ˆæ–°æ–¹æ³•ï¼Œç”¨äºå¯åŠ¨æ—¶ï¼‰"""
        try:
            # è·å–æ–‡ä»¶è·¯å¾„
            file = self.db.query(File).filter(File.id == file_id).first()
            if not file:
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: file_id={file_id}")
                return False
            
            return self.add_task(file_id, file.file_path, task_type, priority)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå¾…å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def add_task(self, file_id: int, file_path: str, task_type: str, priority: int = 0) -> bool:
        """
        æ·»åŠ å¾…å¤„ç†ä»»åŠ¡ï¼ˆå¢å¼ºå»é‡é€»è¾‘ï¼‰
        
        Args:
            file_id: æ–‡ä»¶ID
            file_path: æ–‡ä»¶è·¯å¾„
            task_type: ä»»åŠ¡ç±»å‹
            priority: ä¼˜å…ˆçº§ï¼ˆæ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ ä»»åŠ¡
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„å¾…å¤„ç†ä»»åŠ¡ï¼ˆpendingæˆ–processingçŠ¶æ€ï¼‰
            existing_task = self.db.query(PendingTask).filter(
                and_(
                    PendingTask.file_id == file_id,
                    PendingTask.task_type == task_type,
                    PendingTask.status.in_(["pending", "processing"])
                )
            ).first()
            
            if existing_task:
                # å¦‚æœæ–°ä»»åŠ¡ä¼˜å…ˆçº§æ›´é«˜ï¼Œæ›´æ–°ç°æœ‰ä»»åŠ¡çš„ä¼˜å…ˆçº§
                if priority > existing_task.priority:
                    existing_task.priority = priority
                    self.db.commit()
                    logger.info(f"æ›´æ–°ç°æœ‰ä»»åŠ¡ä¼˜å…ˆçº§: file_id={file_id}, task_type={task_type}, æ–°ä¼˜å…ˆçº§={priority}")
                else:
                    logger.info(f"ä»»åŠ¡å·²å­˜åœ¨ä¸”ä¼˜å…ˆçº§ä¸ä½äºæ–°ä»»åŠ¡ï¼Œè·³è¿‡æ·»åŠ : file_id={file_id}, task_type={task_type}")
                return True
            
            # åˆ›å»ºæ–°ä»»åŠ¡
            task = PendingTask(
                file_id=file_id,
                file_path=file_path,
                task_type=task_type,
                priority=priority,
                status="pending"
            )
            
            self.db.add(task)
            self.db.commit()
            
            logger.info(f"æ·»åŠ å¾…å¤„ç†ä»»åŠ¡æˆåŠŸ: file_id={file_id}, task_type={task_type}, ä¼˜å…ˆçº§={priority}")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
            self.db.rollback()
            return False
    
    def get_pending_tasks(self, limit: int = 10) -> List[PendingTask]:
        """è·å–å¾…å¤„ç†ä»»åŠ¡åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§å’Œåˆ›å»ºæ—¶é—´æ’åº"""
        try:
            tasks = self.db.query(PendingTask).filter(
                PendingTask.status == "pending"
            ).order_by(
                PendingTask.priority.desc(),
                PendingTask.created_at.asc()
            ).limit(limit).all()
            
            return tasks
            
        except Exception as e:
            logger.error(f"è·å–å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
            return []
    
    def process_task(self, task: PendingTask) -> bool:
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        try:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
            task.status = "processing"
            task.updated_at = datetime.now()
            self.db.commit()
            
            logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡: {task.id}, file_path={task.file_path}, task_type={task.task_type}")
            
            success = False
            
            if task.task_type == "vector_index":
                # å¤„ç†å‘é‡ç´¢å¼•ä»»åŠ¡ï¼ˆå…¼å®¹æ—§ä»»åŠ¡ï¼‰- éœ€è¦å…ˆæŸ¥æ‰¾æ–‡ä»¶
                file = self.db.query(File).filter(File.id == task.file_id).first()
                if not file:
                    raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨: file_id={task.file_id}")
                success = self._process_vector_index_task(file)
            elif task.task_type == "file_import":
                # å¤„ç†æ–‡ä»¶å¯¼å…¥ä»»åŠ¡ï¼ˆç»Ÿä¸€åŸå­æ“ä½œï¼šå…¥åº“+å‘é‡åŒ–ï¼‰- ä¸éœ€è¦é¢„å…ˆæŸ¥æ‰¾æ–‡ä»¶
                success = self._process_file_import_task(task)
            else:
                raise Exception(f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task.task_type}")
            
            if success:
                # ä»»åŠ¡æˆåŠŸå®Œæˆ
                task.status = "completed"
                task.processed_at = datetime.now()
                task.error_message = None
                logger.info(f"ä»»åŠ¡å¤„ç†æˆåŠŸ: {task.id}")
            else:
                # ä»»åŠ¡å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•
                task.retry_count += 1
                if task.retry_count >= task.max_retries:
                    task.status = "failed"
                    task.error_message = "è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"
                    logger.error(f"ä»»åŠ¡å¤„ç†å¤±è´¥ï¼Œè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°: {task.id}")
                else:
                    task.status = "pending"
                    logger.warning(f"ä»»åŠ¡å¤„ç†å¤±è´¥ï¼Œå°†é‡è¯•: {task.id}, é‡è¯•æ¬¡æ•°: {task.retry_count}")
            
            task.updated_at = datetime.now()
            self.db.commit()
            return success
            
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥: {task.id}, é”™è¯¯: {e}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.retry_count += 1
            task.error_message = str(e)
            
            if task.retry_count >= task.max_retries:
                task.status = "failed"
            else:
                task.status = "pending"
            
            task.updated_at = datetime.now()
            self.db.commit()
            return False
    
    def _process_vector_index_task(self, file: File) -> bool:
        """å¤„ç†å‘é‡ç´¢å¼•ä»»åŠ¡"""
        try:
            ai_service = AIService(self.db)
            
            if not ai_service.is_available():
                logger.warning(f"AIæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡å‘é‡ç´¢å¼•: {file.file_path}")
                return True  # è·³è¿‡ä½†ä¸ç®—å¤±è´¥
            
            # åˆ›å»ºæˆ–æ›´æ–°å‘é‡ç´¢å¼•
            # æ³¨æ„ï¼šcreate_embeddings æ–¹æ³•å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†ç°æœ‰ç´¢å¼•çš„æ¸…ç†
            success = ai_service.create_embeddings(file)
            
            if success:
                logger.info(f"å‘é‡ç´¢å¼•å¤„ç†æˆåŠŸ: {file.file_path}")
            else:
                logger.error(f"å‘é‡ç´¢å¼•å¤„ç†å¤±è´¥: {file.file_path}")
            
            return success
            
        except Exception as e:
            logger.error(f"å¤„ç†å‘é‡ç´¢å¼•ä»»åŠ¡å¤±è´¥: {file.file_path}, é”™è¯¯: {e}")
            return False
    
    def _process_file_import_task(self, task: PendingTask) -> bool:
        """
        å¤„ç†æ–‡ä»¶å¯¼å…¥ä»»åŠ¡ï¼ˆå…¥åº“+å‘é‡åŒ–ï¼‰
        è¿™æ˜¯ä¸€ä¸ªåŸå­æ“ä½œï¼ŒåŒ…å«ï¼š
        1. è¯»å–æ–‡ä»¶å†…å®¹
        2. åˆ›å»ºæ•°æ®åº“è®°å½•
        3. æ™ºèƒ½å¤šå±‚æ¬¡å‘é‡åˆ†å—
        
        ç»Ÿä¸€å…¥å£ç‚¹ï¼šæ‰€æœ‰æ–‡ä»¶å¤„ç†åœºæ™¯éƒ½åº”è¯¥ä½¿ç”¨è¿™ä¸ªåŸå­æ“ä½œ
        - æ–‡ä»¶ä¸Šä¼ åå¤„ç†
        - æ–‡ä»¶ä¿®æ”¹åæ›´æ–°
        - ç³»ç»Ÿå¯åŠ¨æ—¶æ‰«æ
        - é‡å»ºç´¢å¼•æ—¶å¤„ç†
        """
        try:
            from pathlib import Path
            from ..models.file import File
            from ..schemas.file import FileCreate
            from .ai_service_langchain import AIService
            import hashlib
            
            # è·å–å½“å‰ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
            pending_count = self._get_pending_tasks_count()
            logger.info(f"ğŸ“‹ å¼€å§‹å¤„ç†æ–‡ä»¶å¯¼å…¥ä»»åŠ¡: {task.file_path} (å¾…å¤„ç†ä»»åŠ¡: {pending_count})")
            
            # 1. è¯»å–æ–‡ä»¶å†…å®¹
            # æ™ºèƒ½å¤„ç†è·¯å¾„ï¼šå¦‚æœtask.file_pathå·²åŒ…å«noteså‰ç¼€åˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™æ·»åŠ 
            if task.file_path.startswith("notes/") or task.file_path.startswith("./notes/"):
                # å·²åŒ…å«å®Œæ•´è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                file_path = Path(task.file_path)
            else:
                # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦æ·»åŠ noteså‰ç¼€
                file_path = Path("./notes") / task.file_path
            
            if not file_path.exists():
                raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"ğŸ“– æ–‡ä»¶å†…å®¹è¯»å–å®Œæˆ: {task.file_path} (å¤§å°: {len(content)}å­—ç¬¦)")
            
            # 2. è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            content_hash = hashlib.sha256(content.encode()).hexdigest()
            
            # 3. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æ–‡ä»¶è®°å½•
            # ç¡®ä¿æŸ¥è¯¢æ—¶ä½¿ç”¨æ ‡å‡†åŒ–çš„è·¯å¾„æ ¼å¼
            normalized_path = task.file_path
            if not normalized_path.startswith("notes/"):
                normalized_path = f"notes/{normalized_path}"
            
            existing_file = self.db.query(File).filter(
                File.file_path == normalized_path,
                File.is_deleted == False
            ).first()
            
            if existing_file:
                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰å˜åŒ–
                if existing_file.content_hash == content_hash:
                    logger.info(f"âœ… æ–‡ä»¶å†…å®¹æœªå˜åŒ–ï¼Œè·³è¿‡å¯¼å…¥: {normalized_path}")
                    return True
                else:
                    # å†…å®¹æœ‰å˜åŒ–ï¼Œæ›´æ–°è®°å½•
                    existing_file.content = content
                    existing_file.content_hash = content_hash
                    existing_file.file_size = len(content.encode('utf-8'))
                    existing_file.updated_at = datetime.now()
                    db_file = existing_file
                    logger.info(f"ğŸ”„ æ›´æ–°ç°æœ‰æ–‡ä»¶è®°å½•: {normalized_path}")
            else:
                # åˆ›å»ºæ–°çš„æ–‡ä»¶è®°å½•
                title = Path(task.file_path).stem
                
                # ç¡®ä¿æ•°æ®åº“ä¸­å­˜å‚¨çš„è·¯å¾„æ ¼å¼ä¸€è‡´ï¼ˆå§‹ç»ˆåŒ…å«noteså‰ç¼€ï¼‰
                normalized_path = task.file_path
                if not normalized_path.startswith("notes/"):
                    normalized_path = f"notes/{normalized_path}"
                
                db_file = File(
                    file_path=normalized_path,
                    title=title,
                    content=content,
                    content_hash=content_hash,
                    file_size=len(content.encode('utf-8')),
                    is_deleted=False
                )
                self.db.add(db_file)
                logger.info(f"ğŸ“ åˆ›å»ºæ–°æ–‡ä»¶è®°å½•: {normalized_path}")
            
            # 4. æäº¤æ•°æ®åº“äº‹åŠ¡
            self.db.commit()
            self.db.refresh(db_file)
            logger.info(f"ğŸ’¾ æ•°æ®åº“è®°å½•ä¿å­˜æˆåŠŸ: {normalized_path}")
            
            # 5. å¼€å§‹æ™ºèƒ½å¤šå±‚æ¬¡å‘é‡åˆ†å—
            ai_service = AIService(self.db)
            if ai_service.is_available():
                logger.info(f"ğŸ¤– å¼€å§‹æ™ºèƒ½å¤šå±‚æ¬¡å‘é‡åˆ†å—: {normalized_path}")
                
                # è°ƒç”¨æ™ºèƒ½åˆ†å—ï¼Œå¹¶ä¼ é€’è¿›åº¦å›è°ƒ
                vector_success = ai_service.create_embeddings(
                    db_file, 
                    progress_callback=lambda step, message: self._log_chunking_progress(
                        normalized_path, step, message
                    )
                )
                
                if vector_success:
                    # è·å–æœ€æ–°çš„ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
                    remaining_count = self._get_pending_tasks_count()
                    logger.info(f"ğŸ‰ æ–‡ä»¶å¤„ç†å®Œå…¨æˆåŠŸ: {normalized_path} | å‰©ä½™ä»»åŠ¡: {remaining_count}")
                else:
                    logger.error(f"âŒ å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥: {normalized_path}")
                    return False
            else:
                logger.warning(f"âš ï¸ AIæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡å‘é‡ç´¢å¼•: {normalized_path}")
            
            return True
            
        except Exception as e:
            # å°è¯•è·å–æ ‡å‡†åŒ–è·¯å¾„ç”¨äºé”™è¯¯æ—¥å¿—
            try:
                normalized_path = task.file_path
                if not normalized_path.startswith("notes/"):
                    normalized_path = f"notes/{normalized_path}"
                logger.error(f"ğŸ’¥ æ–‡ä»¶å¯¼å…¥ä»»åŠ¡å¤±è´¥: {normalized_path}, é”™è¯¯: {e}")
            except:
                logger.error(f"ğŸ’¥ æ–‡ä»¶å¯¼å…¥ä»»åŠ¡å¤±è´¥: {task.file_path}, é”™è¯¯: {e}")
            self.db.rollback()
            return False
    
    def _get_pending_tasks_count(self) -> int:
        """è·å–å¾…å¤„ç†ä»»åŠ¡æ•°é‡"""
        try:
            return self.db.query(PendingTask).filter(
                PendingTask.status == "pending"
            ).count()
        except Exception:
            return 0
    
    def _log_chunking_progress(self, file_path: str, step: str, message: str):
        """è®°å½•åˆ†å—è¿›åº¦"""
        remaining_count = self._get_pending_tasks_count()
        logger.info(f"ğŸ”§ [{step}] {message} | æ–‡ä»¶: {file_path} | å‰©ä½™ä»»åŠ¡: {remaining_count}")
    
    def process_all_pending_tasks(self):
        """å¤„ç†æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡"""
        if not self._acquire_lock():
            return
        
        try:
            self.is_running = True
            start_time = datetime.now()
            processed_count = 0
            success_count = 0
            
            logger.info("å¼€å§‹å¤„ç†å¾…å¤„ç†ä»»åŠ¡é˜Ÿåˆ—")
            
            while True:
                # è·å–ä¸€æ‰¹å¾…å¤„ç†ä»»åŠ¡
                tasks = self.get_pending_tasks(limit=5)
                
                if not tasks:
                    logger.info("æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œç»“æŸå¤„ç†")
                    break
                
                # å¤„ç†æ¯ä¸ªä»»åŠ¡
                for task in tasks:
                    task_start_time = datetime.now()
                    logger.info(f"ğŸš€ å¼€å§‹å¤„ç†ä»»åŠ¡: {task.id}, æ–‡ä»¶: {task.file_path}, ç±»å‹: {task.task_type}")
                    
                    try:
                        if self.process_task(task):
                            success_count += 1
                            task_duration = (datetime.now() - task_start_time).total_seconds()
                            logger.info(f"âœ… ä»»åŠ¡å¤„ç†æˆåŠŸ: {task.id}, è€—æ—¶: {task_duration:.2f}ç§’")
                        else:
                            task_duration = (datetime.now() - task_start_time).total_seconds()
                            logger.error(f"âŒ ä»»åŠ¡å¤„ç†å¤±è´¥: {task.id}, è€—æ—¶: {task_duration:.2f}ç§’")
                    except Exception as e:
                        task_duration = (datetime.now() - task_start_time).total_seconds()
                        logger.error(f"ğŸ’¥ ä»»åŠ¡å¤„ç†å¼‚å¸¸: {task.id}, è€—æ—¶: {task_duration:.2f}ç§’, é”™è¯¯: {e}")
                    
                    processed_count += 1
                    
                    # æ£€æŸ¥æ˜¯å¦è¿è¡Œæ—¶é—´è¿‡é•¿ï¼ˆå¢åŠ åˆ°15åˆ†é’Ÿï¼‰
                    total_duration = (datetime.now() - start_time).total_seconds()
                    if total_duration > 900:  # 15åˆ†é’Ÿ = 900ç§’
                        logger.warning(f"ä»»åŠ¡å¤„ç†æ—¶é—´è¿‡é•¿({total_duration:.1f}ç§’)ï¼Œæš‚åœå¤„ç†ä»¥é¿å…é˜»å¡")
                        break
                    
                    # æ£€æŸ¥å•ä¸ªä»»åŠ¡æ˜¯å¦è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰
                    if task_duration > 300:  # 5åˆ†é’Ÿ = 300ç§’
                        logger.warning(f"â° å•ä¸ªä»»åŠ¡å¤„ç†è¶…æ—¶: {task.id}, è€—æ—¶: {task_duration:.2f}ç§’")
                
                # çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…è¿‡åº¦å ç”¨èµ„æº
                time.sleep(0.1)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            logger.info(f"ğŸ‰ ä»»åŠ¡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {processed_count} ä¸ªä»»åŠ¡ï¼ŒæˆåŠŸ {success_count} ä¸ªï¼Œè€—æ—¶ {duration:.2f} ç§’")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ å¤„ç†å¾…å¤„ç†ä»»åŠ¡é˜Ÿåˆ—å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        finally:
            self.is_running = False
            self._release_lock()
            logger.info("ğŸ”“ ä»»åŠ¡å¤„ç†å™¨å·²é‡Šæ”¾é”å¹¶åœæ­¢")
    
    def cleanup_old_tasks(self, days: int = 7):
        """æ¸…ç†æ—§çš„å·²å®Œæˆä»»åŠ¡"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            
            deleted_count = self.db.query(PendingTask).filter(
                and_(
                    PendingTask.status.in_(["completed", "failed"]),
                    PendingTask.updated_at < cutoff_date
                )
            ).delete()
            
            self.db.commit()
            
            if deleted_count > 0:
                logger.info(f"æ¸…ç†äº† {deleted_count} ä¸ªæ—§ä»»åŠ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§ä»»åŠ¡å¤±è´¥: {e}")
            self.db.rollback() 
    
    def clear_duplicate_pending_tasks(self) -> int:
        """
        æ¸…ç†é‡å¤çš„å¾…å¤„ç†ä»»åŠ¡
        å¯¹äºç›¸åŒfile_idå’Œtask_typeçš„pendingä»»åŠ¡ï¼Œåªä¿ç•™ä¼˜å…ˆçº§æœ€é«˜ä¸”æœ€æ–°çš„ä¸€ä¸ª
        
        Returns:
            int: æ¸…ç†çš„é‡å¤ä»»åŠ¡æ•°é‡
        """
        try:
            # æŸ¥æ‰¾é‡å¤ä»»åŠ¡ç»„
            duplicate_groups = self.db.execute(text("""
                SELECT file_id, task_type, COUNT(*) as count
                FROM pending_tasks 
                WHERE status = 'pending'
                GROUP BY file_id, task_type
                HAVING COUNT(*) > 1
            """)).fetchall()
            
            removed_count = 0
            
            for group in duplicate_groups:
                file_id = group.file_id
                task_type = group.task_type
                
                # è·å–è¯¥ç»„çš„æ‰€æœ‰ä»»åŠ¡ï¼ŒæŒ‰ä¼˜å…ˆçº§é™åºã€åˆ›å»ºæ—¶é—´é™åºæ’åº
                tasks = self.db.query(PendingTask).filter(
                    and_(
                        PendingTask.file_id == file_id,
                        PendingTask.task_type == task_type,
                        PendingTask.status == "pending"
                    )
                ).order_by(
                    PendingTask.priority.desc(),
                    PendingTask.created_at.desc()
                ).all()
                
                if len(tasks) > 1:
                    # ä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆä¼˜å…ˆçº§æœ€é«˜ä¸”æœ€æ–°çš„ï¼‰ï¼Œåˆ é™¤å…¶ä»–çš„
                    keep_task = tasks[0]
                    tasks_to_remove = tasks[1:]
                    
                    for task in tasks_to_remove:
                        self.db.delete(task)
                        removed_count += 1
                    
                    logger.info(f"æ¸…ç†é‡å¤ä»»åŠ¡ç»„: file_id={file_id}, task_type={task_type}, "
                              f"ä¿ç•™ä»»åŠ¡ID={keep_task.id}(ä¼˜å…ˆçº§={keep_task.priority}), "
                              f"åˆ é™¤{len(tasks_to_remove)}ä¸ªé‡å¤ä»»åŠ¡")
            
            self.db.commit()
            logger.info(f"æ¸…ç†é‡å¤ä»»åŠ¡å®Œæˆï¼Œå…±åˆ é™¤ {removed_count} ä¸ªé‡å¤ä»»åŠ¡")
            return removed_count
            
        except Exception as e:
            logger.error(f"æ¸…ç†é‡å¤ä»»åŠ¡å¤±è´¥: {e}")
            self.db.rollback()
            return 0
    
    def get_task_statistics(self) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            if _task_stats_cache["data"] and datetime.now() - _task_stats_cache["last_update"] < timedelta(seconds=_task_stats_cache["cache_duration"]):
                return _task_stats_cache["data"]
            
            stats = {}
            
            # æŒ‰çŠ¶æ€ç»Ÿè®¡
            status_stats = self.db.execute(text("""
                SELECT status, COUNT(*) as count
                FROM pending_tasks 
                GROUP BY status
            """)).fetchall()
            
            stats['by_status'] = {row.status: row.count for row in status_stats}
            
            # æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡
            type_stats = self.db.execute(text("""
                SELECT task_type, COUNT(*) as count
                FROM pending_tasks 
                WHERE status = 'pending'
                GROUP BY task_type
            """)).fetchall()
            
            stats['by_type'] = {row.task_type: row.count for row in type_stats}
            
            # é‡å¤ä»»åŠ¡ç»Ÿè®¡
            duplicate_stats = self.db.execute(text("""
                SELECT file_id, task_type, COUNT(*) as count
                FROM pending_tasks 
                WHERE status = 'pending'
                GROUP BY file_id, task_type
                HAVING COUNT(*) > 1
            """)).fetchall()
            
            stats['duplicates'] = len(duplicate_stats)
            stats['total_duplicate_tasks'] = sum(row.count - 1 for row in duplicate_stats)
            
            # æ›´æ–°ç¼“å­˜
            _task_stats_cache["data"] = stats
            _task_stats_cache["last_update"] = datetime.now()
            
            return stats
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def get_processor_status(self) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡å¤„ç†å™¨è¿è¡ŒçŠ¶æ€"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†ä»»åŠ¡
            pending_count = self._get_pending_tasks_count()
            
            # æ£€æŸ¥é”æ–‡ä»¶
            if not self.lock_file.exists():
                if pending_count > 0:
                    return {
                        "running": False,
                        "pid": None,
                        "status": "idle",
                        "message": f"ä»»åŠ¡å¤„ç†å™¨ç©ºé—²ä¸­ï¼Œæœ‰ {pending_count} ä¸ªå¾…å¤„ç†ä»»åŠ¡",
                        "pending_tasks": pending_count
                    }
                else:
                    return {
                        "running": False,
                        "pid": None,
                        "status": "idle",
                        "message": "ä»»åŠ¡å¤„ç†å™¨ç©ºé—²ä¸­ï¼Œæš‚æ— å¾…å¤„ç†ä»»åŠ¡",
                        "pending_tasks": 0
                    }
            
            # è¯»å–é”æ–‡ä»¶ä¸­çš„PID
            try:
                with open(self.lock_file, 'r') as f:
                    pid_str = f.read().strip()
                    if not pid_str:
                        # ç©ºé”æ–‡ä»¶ï¼Œæ¸…ç†å¹¶è¿”å›ç©ºé—²çŠ¶æ€
                        self.lock_file.unlink()
                        return {
                            "running": False,
                            "pid": None,
                            "status": "idle",
                            "message": "é”æ–‡ä»¶æŸåå·²æ¸…ç†ï¼Œä»»åŠ¡å¤„ç†å™¨ç©ºé—²ä¸­",
                            "pending_tasks": pending_count
                        }
                    
                    pid = int(pid_str)
                    
                    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦çœŸçš„åœ¨è¿è¡Œ
                    if self._is_process_running(pid):
                        # è¿›ç¨‹è¿˜åœ¨è¿è¡Œï¼Œå‡è®¾æ˜¯ä»»åŠ¡å¤„ç†å™¨ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
                        return {
                            "running": True,
                            "pid": pid,
                            "status": "running",
                            "message": f"ä»»åŠ¡å¤„ç†å™¨æ­£åœ¨è¿è¡Œ (PID: {pid})",
                            "pending_tasks": pending_count
                        }
                    else:
                        # è¿›ç¨‹ç¡®å®å·²æ­»ï¼Œå®‰å…¨æ¸…ç†é”æ–‡ä»¶
                        logger.info(f"æ£€æµ‹åˆ°æ­»é”æ–‡ä»¶(PID: {pid}å·²é€€å‡º)ï¼Œæ¸…ç†é”æ–‡ä»¶")
                        self.lock_file.unlink()
                        return {
                            "running": False,
                            "pid": None,
                            "status": "idle",
                            "message": "ä»»åŠ¡å¤„ç†å™¨è¿›ç¨‹å·²åœæ­¢ï¼Œç°åœ¨ç©ºé—²ä¸­",
                            "pending_tasks": pending_count
                        }
                        
            except (ValueError, OSError) as e:
                # é”æ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–è¯»å–å¤±è´¥
                logger.error(f"è¯»å–é”æ–‡ä»¶å¤±è´¥: {e}")
                try:
                    self.lock_file.unlink()
                except:
                    pass
                return {
                    "running": False,
                    "pid": None,
                    "status": "error",
                    "message": f"é”æ–‡ä»¶è¯»å–å¤±è´¥: {e}",
                    "pending_tasks": pending_count
                }
                
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å¤„ç†å™¨çŠ¶æ€å¤±è´¥: {e}")
            return {
                "running": False,
                "pid": None,
                "status": "error",
                "message": f"çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}",
                "pending_tasks": 0
            }
    
    def start_processor(self, force: bool = False) -> Dict[str, Any]:
        """æ‰‹åŠ¨å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨"""
        try:
            # æ£€æŸ¥å½“å‰çŠ¶æ€
            current_status = self.get_processor_status()
            
            if current_status["running"] and not force:
                return {
                    "success": False,
                    "message": f"ä»»åŠ¡å¤„ç†å™¨å·²åœ¨è¿è¡Œä¸­ (PID: {current_status['pid']})",
                    "status": current_status
                }
            
            # å¦‚æœforce=Trueï¼Œå…ˆæ¸…ç†å¯èƒ½çš„æ­»é”
            if force:
                logger.info("ğŸ§¹ å¼ºåˆ¶å¯åŠ¨ï¼Œæ¸…ç†å¯èƒ½çš„æ­»é”æ–‡ä»¶")
                self._release_lock()
            
            # å¯åŠ¨å¤„ç†å™¨
            logger.info("ğŸš€ æ‰‹åŠ¨å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨")
            self.process_all_pending_tasks()
            
            return {
                "success": True,
                "message": "ä»»åŠ¡å¤„ç†å™¨å¯åŠ¨æˆåŠŸ",
                "status": self.get_processor_status()
            }
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨å¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"å¯åŠ¨å¤±è´¥: {e}",
                "status": self.get_processor_status()
            }
    
    def stop_processor(self) -> Dict[str, Any]:
        """åœæ­¢ä»»åŠ¡å¤„ç†å™¨ï¼ˆé€šè¿‡åˆ é™¤é”æ–‡ä»¶ï¼‰"""
        try:
            current_status = self.get_processor_status()
            
            if not current_status["running"]:
                return {
                    "success": False,
                    "message": "ä»»åŠ¡å¤„ç†å™¨æœªè¿è¡Œ",
                    "status": current_status
                }
            
            # åˆ é™¤é”æ–‡ä»¶æ¥åœæ­¢å¤„ç†å™¨
            self._release_lock()
            
            logger.info("ğŸ›‘ æ‰‹åŠ¨åœæ­¢ä»»åŠ¡å¤„ç†å™¨")
            
            return {
                "success": True,
                "message": "ä»»åŠ¡å¤„ç†å™¨åœæ­¢ä¿¡å·å·²å‘é€",
                "status": self.get_processor_status()
            }
            
        except Exception as e:
            logger.error(f"åœæ­¢ä»»åŠ¡å¤„ç†å™¨å¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"åœæ­¢å¤±è´¥: {e}",
                "status": self.get_processor_status()
            }