"""
æ–‡ä»¶ä¸Šä¼ è·¯ç”±å¤„ç†æ¨¡å—
æ”¯æŒå›¾ç‰‡ã€PDFã€DOCXæ–‡ä»¶çš„ä¸Šä¼ å’Œå¤„ç†
"""
import os
import uuid
import tempfile
from typing import List, Optional, Dict, Any, Tuple
from fastapi import APIRouter, File, UploadFile, HTTPException, Request, Form
from fastapi.responses import FileResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
import logging
from pathlib import Path
import time
import httpx
import json
from config import settings

# æ–‡æ¡£å¤„ç†ç›¸å…³å¯¼å…¥
try:
    from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    DOCUMENT_PROCESSING_AVAILABLE = True
except ImportError as e:
    logging.warning(f"æ–‡æ¡£å¤„ç†ä¾èµ–æœªå®‰è£…: {e}")
    DOCUMENT_PROCESSING_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
ALLOWED_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
ALLOWED_DOCUMENT_EXTENSIONS = {'.pdf', '.docx'}
ALLOWED_EXTENSIONS = ALLOWED_IMAGE_EXTENSIONS | ALLOWED_DOCUMENT_EXTENSIONS
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB (æ–‡æ¡£æ–‡ä»¶å¯èƒ½è¾ƒå¤§)

# åˆ›å»ºä¸Šä¼ ç›®å½•
UPLOAD_DIR = Path("/app/uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# OCRæœåŠ¡é…ç½®
OCR_BASE_URL = "http://ocr:7860"

class DocumentService:
    """æ–‡æ¡£å¤„ç†æœåŠ¡ç±»"""
    
    def __init__(self):
        if DOCUMENT_PROCESSING_AVAILABLE:
            # é…ç½®æ–‡æœ¬åˆ†å‰²å™¨ï¼Œç”¨äºå¤„ç†å¤§æ–‡æ¡£
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=2000,
                chunk_overlap=200,
                length_function=len,
            )
        else:
            self.text_splitter = None
    
    async def process_document(self, file_content: bytes, filename: str) -> Dict[str, Any]:
        """
        å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£æ–‡ä»¶å¹¶æå–å…¶å†…å®¹
        
        Args:
            file_content: æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
            filename: æ–‡ä»¶å
            
        Returns:
            åŒ…å«æå–æ–‡æœ¬å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if not DOCUMENT_PROCESSING_AVAILABLE:
            raise Exception("æ–‡æ¡£å¤„ç†åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·å®‰è£…ç›¸å…³ä¾èµ–")
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        file_extension = Path(filename).suffix.lower()
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            temp_file_path = temp_file.name
            temp_file.write(file_content)
        
        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åŠ è½½å™¨
            if file_extension == '.pdf':
                docs, metadata = self._process_pdf(temp_file_path)
            elif file_extension == '.docx':
                docs, metadata = self._process_docx(temp_file_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}")
            
            # æå–æ–‡æœ¬å†…å®¹
            full_text = "\n\n".join([doc.page_content for doc in docs])
            
            # è¿”å›è§£æç»“æœ
            return {
                "filename": filename,
                "content": full_text,
                "page_count": metadata.get("page_count", 1),
                "file_type": metadata.get("file_type", "unknown"),
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: process_document")
            raise Exception(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file_path):
                try:
                    os.remove(temp_file_path)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: process_document")
    
    def _process_pdf(self, file_path: str) -> Tuple[List[Any], Dict[str, Any]]:
        """å¤„ç†PDFæ–‡ä»¶"""
        try:
            loader = PyPDFLoader(file_path)
            docs = loader.load()
            
            # æå–å…ƒæ•°æ®
            metadata = {
                "page_count": len(docs),
                "file_type": "PDF"
            }
            
            return docs, metadata
        except Exception as e:
            logger.error(f"PDFå¤„ç†å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: _process_pdf")
            raise Exception(f"PDFæ–‡ä»¶è§£æå¤±è´¥: {str(e)}")
    
    def _process_docx(self, file_path: str) -> Tuple[List[Any], Dict[str, Any]]:
        """å¤„ç†DOCXæ–‡ä»¶"""
        try:
            loader = Docx2txtLoader(file_path)
            docs = loader.load()
            
            # æå–å…ƒæ•°æ® (DOCXåŠ è½½å™¨é€šå¸¸åªè¿”å›ä¸€ä¸ªæ–‡æ¡£å¯¹è±¡)
            metadata = {
                "page_count": 1,  # DOCXé€šå¸¸ä¸åˆ†é¡µ
                "file_type": "DOCX"
            }
            
            return docs, metadata
        except Exception as e:
            logger.error(f"DOCXå¤„ç†å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: _process_docx")
            raise Exception(f"DOCXæ–‡ä»¶è§£æå¤±è´¥: {str(e)}")

# åˆå§‹åŒ–æ–‡æ¡£æœåŠ¡
document_service = DocumentService()

def is_image_file(filename: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„å›¾ç‰‡æ ¼å¼"""
    return Path(filename).suffix.lower() in ALLOWED_IMAGE_EXTENSIONS

def is_document_file(filename: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„æ–‡æ¡£æ ¼å¼"""
    return Path(filename).suffix.lower() in ALLOWED_DOCUMENT_EXTENSIONS

def is_supported_file(filename: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
    return Path(filename).suffix.lower() in ALLOWED_EXTENSIONS

def get_file_type(filename: str) -> str:
    """è·å–æ–‡ä»¶ç±»å‹"""
    extension = Path(filename).suffix.lower()
    if extension in ALLOWED_IMAGE_EXTENSIONS:
        return "image"
    elif extension in ALLOWED_DOCUMENT_EXTENSIONS:
        return "document"
    else:
        return "unknown"

def generate_unique_filename(original_filename: str) -> str:
    """ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å"""
    # è·å–æ–‡ä»¶æ‰©å±•å
    file_extension = Path(original_filename).suffix
    # ç”Ÿæˆå”¯ä¸€ID
    unique_id = str(uuid.uuid4())
    # æ·»åŠ æ—¶é—´æˆ³
    timestamp = str(int(time.time()))
    return f"{timestamp}_{unique_id}{file_extension}"

@router.post("/upload")
async def upload_file(
    request: Request,
    file: UploadFile = File(...)
) -> dict:
    """æ–‡ä»¶ä¸Šä¼ æ¥å£
    
    Args:
        request: FastAPIè¯·æ±‚å¯¹è±¡
        file: ä¸Šä¼ çš„æ–‡ä»¶
        
    Returns:
        ä¸Šä¼ ç»“æœä¿¡æ¯
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not file.filename:
            raise HTTPException(
                status_code=400,
                detail="æœªé€‰æ‹©æ–‡ä»¶"
            )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        content = await file.read()
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ {MAX_FILE_SIZE // (1024*1024)}MB"
            )
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not is_supported_file(file.filename):
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œæ”¯æŒçš„æ ¼å¼: {', '.join(ALLOWED_EXTENSIONS)}"
            )
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        unique_filename = generate_unique_filename(file.filename)
        file_path = UPLOAD_DIR / unique_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            buffer.write(content)
        
        # æ„é€ æ–‡ä»¶è®¿é—®URL
        file_url = f"/api/v1/files/{unique_filename}"
        file_type = get_file_type(file.filename)
        
        logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file.filename} -> {unique_filename}, ç±»å‹: {file_type} - æ–‡ä»¶: {__file__} - å‡½æ•°: upload_file")
        
        return {
            "success": True,
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
            "data": {
                "filename": unique_filename,
                "original_filename": file.filename,
                "file_url": file_url,
                "file_size": len(content),
                "file_type": file_type,
                "content_type": file.content_type
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: upload_file")
        raise HTTPException(
            status_code=500,
            detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
        )

@router.get("/files/{filename}")
async def get_file(filename: str):
    """è·å–ä¸Šä¼ çš„æ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶å
        
    Returns:
        æ–‡ä»¶å“åº”
    """
    try:
        file_path = UPLOAD_DIR / filename
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not file_path.exists():
            raise HTTPException(
                status_code=404,
                detail="æ–‡ä»¶ä¸å­˜åœ¨"
            )
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæ”¯æŒçš„ç±»å‹
        if not is_supported_file(filename):
            raise HTTPException(
                status_code=400,
                detail="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"
            )
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½®åˆé€‚çš„åª’ä½“ç±»å‹
        file_type = get_file_type(filename)
        if file_type == "image":
            media_type = "image/*"
        elif file_type == "document":
            extension = Path(filename).suffix.lower()
            if extension == '.pdf':
                media_type = "application/pdf"
            elif extension == '.docx':
                media_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            else:
                media_type = "application/octet-stream"
        else:
            media_type = "application/octet-stream"
        
        logger.info(f"è®¿é—®æ–‡ä»¶: {filename}, ç±»å‹: {file_type} - æ–‡ä»¶: {__file__} - å‡½æ•°: get_file")
        
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type=media_type
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: get_file")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–æ–‡ä»¶å¤±è´¥: {str(e)}"
        )

@router.delete("/files/{filename}")
async def delete_file(filename: str):
    """åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶å
        
    Returns:
        åˆ é™¤ç»“æœ
    """
    try:
        file_path = UPLOAD_DIR / filename
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not file_path.exists():
            raise HTTPException(
                status_code=404,
                detail="æ–‡ä»¶ä¸å­˜åœ¨"
            )
        
        # åˆ é™¤æ–‡ä»¶
        file_path.unlink()
        
        logger.info(f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {filename} - æ–‡ä»¶: {__file__} - å‡½æ•°: delete_file")
        
        return {
            "success": True,
            "message": "æ–‡ä»¶åˆ é™¤æˆåŠŸ",
            "filename": filename
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: delete_file")
        raise HTTPException(
            status_code=500,
            detail=f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {str(e)}"
        )

@router.get("/files")
async def list_files():
    """è·å–æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        æ–‡ä»¶åˆ—è¡¨
    """
    try:
        files = []
        for file_path in UPLOAD_DIR.glob("*"):
            if file_path.is_file() and is_supported_file(file_path.name):
                file_stat = file_path.stat()
                file_type = get_file_type(file_path.name)
                files.append({
                    "filename": file_path.name,
                    "size": file_stat.st_size,
                    "file_type": file_type,
                    "created_time": file_stat.st_ctime,
                    "modified_time": file_stat.st_mtime
                })
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        files.sort(key=lambda x: x["created_time"], reverse=True)
        
        logger.info(f"è·å–æ–‡ä»¶åˆ—è¡¨æˆåŠŸï¼Œå…± {len(files)} ä¸ªæ–‡ä»¶ - æ–‡ä»¶: {__file__} - å‡½æ•°: list_files")
        
        return {
            "success": True,
            "data": {
                "files": files,
                "total": len(files)
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: list_files")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}"
        )

@router.post("/upload-and-convert")
async def upload_and_convert_to_markdown(
    request: Request,
    file: UploadFile = File(...)
) -> dict:
    """æ–‡ä»¶ä¸Šä¼ å¹¶è½¬æ¢ä¸ºæ–‡æœ¬æ¥å£
    æ”¯æŒå›¾ç‰‡ï¼ˆé€šè¿‡OCRï¼‰ã€PDFã€DOCXæ–‡ä»¶çš„å¤„ç†
    
    Args:
        request: FastAPIè¯·æ±‚å¯¹è±¡
        file: ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆå›¾ç‰‡ã€PDFã€DOCXï¼‰
        
    Returns:
        åŒ…å«æ–‡æœ¬å†…å®¹çš„èŠå¤©æ ¼å¼å“åº”
    """
    try:
        start_time = time.time()
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶è½¬æ¢: {file.filename} - æ–‡ä»¶: {__file__} - å‡½æ•°: upload_and_convert_to_markdown")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not file.filename:
            raise HTTPException(
                status_code=400,
                detail="æœªé€‰æ‹©æ–‡ä»¶"
            )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        content = await file.read()
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ {MAX_FILE_SIZE // (1024*1024)}MB"
            )
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not is_supported_file(file.filename):
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œæ”¯æŒçš„æ ¼å¼: {', '.join(ALLOWED_EXTENSIONS)}"
            )
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åå¹¶ä¿å­˜
        unique_filename = generate_unique_filename(file.filename)
        file_path = UPLOAD_DIR / unique_filename
        file_type = get_file_type(file.filename)
        
        with open(file_path, "wb") as buffer:
            buffer.write(content)
        
        logger.info(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {unique_filename}, ç±»å‹: {file_type} - æ–‡ä»¶: {__file__} - å‡½æ•°: upload_and_convert_to_markdown")
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
        try:
            if file_type == "image":
                # å›¾ç‰‡æ–‡ä»¶ - ä½¿ç”¨OCRæœåŠ¡
                text_content = await call_ocr_service(file_path, file.filename)
                processing_type = "å›¾ç‰‡OCRåˆ†æ"
                content_icon = "ğŸ“·"
            elif file_type == "document":
                # æ–‡æ¡£æ–‡ä»¶ - ä½¿ç”¨æ–‡æ¡£å¤„ç†æœåŠ¡
                doc_result = await document_service.process_document(content, file.filename)
                text_content = doc_result['content']
                processing_type = f"{doc_result['file_type']}æ–‡æ¡£è§£æ"
                content_icon = "ğŸ“„" if doc_result['file_type'] == "PDF" else "ğŸ“"
            else:
                raise Exception(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
            
            logger.info(f"{processing_type}æˆåŠŸï¼Œç”¨æ—¶: {time.time() - start_time:.2f}ç§’ - æ–‡ä»¶: {__file__} - å‡½æ•°: upload_and_convert_to_markdown")
            
            # æ„é€ èŠå¤©æ ¼å¼çš„å“åº” - ä¼˜åŒ–åŒ»ç–—è¯„ä»·åœºæ™¯
            chat_response = {
                "success": True,
                "message": f"{processing_type}æˆåŠŸ",
                "data": {
                    "type": "chat_message",
                    "role": "assistant", 
                    "content": f"{content_icon} **{processing_type}å®Œæˆ**\n\næˆ‘å·²ç»åˆ†æäº†æ‚¨ä¸Šä¼ çš„{file_type}æ–‡ä»¶ `{file.filename}`ï¼Œä»¥ä¸‹æ˜¯æå–çš„å†…å®¹ï¼š\n\n---\n\n{text_content}\n\n---\n\nğŸ’¡ **è¯´æ˜**: å¦‚æœæ‚¨éœ€è¦å¯¹æ­¤å†…å®¹è¿›è¡ŒåŒ»ç–—è¯„ä»·åˆ†æï¼Œè¯·å‘Šè¯‰æˆ‘å…·ä½“éœ€è¦åˆ†æçš„æ–¹é¢ï¼ˆå¦‚è´¨é‡è¯„ä»·ã€é¡¹ç›®è¯„ä¼°ã€é£é™©åˆ†æç­‰ï¼‰ã€‚",
                    "original_filename": file.filename,
                    "file_url": f"/api/v1/files/{unique_filename}",
                    "processing_time": f"{time.time() - start_time:.2f}ç§’",
                    "file_type": file_type,
                    "processing_type": processing_type
                }
            }
            
            return chat_response
            
        except Exception as processing_error:
            logger.error(f"{processing_type if 'processing_type' in locals() else 'æ–‡ä»¶å¤„ç†'}å¤±è´¥: {str(processing_error)} - æ–‡ä»¶: {__file__} - å‡½æ•°: upload_and_convert_to_markdown")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹ç”Ÿæˆä¸åŒçš„é”™è¯¯æ¶ˆæ¯
            if file_type == "image":
                error_content = f"âŒ **å›¾ç‰‡åˆ†æå¤±è´¥**\n\næŠ±æ­‰ï¼Œæ— æ³•è§£æå›¾ç‰‡ `{file.filename}` çš„å†…å®¹ã€‚\n\n**å¯èƒ½çš„åŸå› ï¼š**\n- ğŸ“· å›¾ç‰‡å†…å®¹è¿‡äºå¤æ‚æˆ–æ¨¡ç³Š\n- ğŸ” å›¾ç‰‡åˆ†è¾¨ç‡ä¸è¶³ï¼Œå»ºè®®ä½¿ç”¨é«˜æ¸…å›¾ç‰‡\n- ğŸŒ OCRæœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n- ğŸ“„ å›¾ç‰‡ä¸­å¯èƒ½æ²¡æœ‰å¯è¯†åˆ«çš„æ–‡å­—å†…å®¹\n\n**å»ºè®®ï¼š**\n- è¯·å°è¯•ä¸Šä¼ æ›´æ¸…æ™°çš„å›¾ç‰‡\n- ç¡®ä¿å›¾ç‰‡ä¸­åŒ…å«æ¸…æ™°çš„æ–‡å­—å†…å®¹\n- å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ\n\næ‚¨ä¹Ÿå¯ä»¥ç›´æ¥æè¿°å›¾ç‰‡å†…å®¹ï¼Œæˆ‘ä¼šåŸºäºæ‚¨çš„æè¿°è¿›è¡ŒåŒ»ç–—è¯„ä»·åˆ†æã€‚"
            elif file_type == "document":
                error_content = f"âŒ **æ–‡æ¡£è§£æå¤±è´¥**\n\næŠ±æ­‰ï¼Œæ— æ³•è§£ææ–‡æ¡£ `{file.filename}` çš„å†…å®¹ã€‚\n\n**å¯èƒ½çš„åŸå› ï¼š**\n- ğŸ“„ æ–‡æ¡£æ ¼å¼æŸåæˆ–ä¸æ ‡å‡†\n- ğŸ”’ æ–‡æ¡£å¯èƒ½æœ‰å¯†ç ä¿æŠ¤\n- ğŸŒ æ–‡æ¡£å¤„ç†æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n- ğŸ“ æ–‡æ¡£å†…å®¹è¿‡äºå¤æ‚\n\n**å»ºè®®ï¼š**\n- è¯·ç¡®ä¿æ–‡æ¡£æ ¼å¼æ­£ç¡®ä¸”æœªæŸå\n- å¦‚æœæ˜¯PDFï¼Œè¯·ç¡®ä¿æ²¡æœ‰å¯†ç ä¿æŠ¤\n- å¦‚æœæ˜¯DOCXï¼Œè¯·ç¡®ä¿æ˜¯æ ‡å‡†æ ¼å¼\n- å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ\n\næ‚¨ä¹Ÿå¯ä»¥ç›´æ¥å¤åˆ¶ç²˜è´´æ–‡æ¡£å†…å®¹ï¼Œæˆ‘ä¼šåŸºäºæ‚¨æä¾›çš„æ–‡æœ¬è¿›è¡ŒåŒ»ç–—è¯„ä»·åˆ†æã€‚"
            else:
                error_content = f"âŒ **æ–‡ä»¶å¤„ç†å¤±è´¥**\n\næŠ±æ­‰ï¼Œæ— æ³•å¤„ç†æ–‡ä»¶ `{file.filename}`ã€‚\n\né”™è¯¯ä¿¡æ¯ï¼š{str(processing_error)}"
            
            return {
                "success": False,
                "message": f"{file_type}å¤„ç†å¤±è´¥",
                "data": {
                    "type": "chat_message",
                    "role": "assistant",
                    "content": error_content,
                    "error": str(processing_error),
                    "original_filename": file.filename,
                    "file_url": f"/api/v1/files/{unique_filename}",
                    "file_type": file_type,
                    "analysis_failed": True
                }
            }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å’Œè½¬æ¢å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: upload_and_convert_to_markdown")
        raise HTTPException(
            status_code=500,
            detail=f"æ–‡ä»¶ä¸Šä¼ å’Œè½¬æ¢å¤±è´¥: {str(e)}"
        )

async def call_ocr_service(file_path: Path, original_filename: str) -> str:
    """è°ƒç”¨OCRæœåŠ¡è¿›è¡Œå›¾ç‰‡è½¬markdownè½¬æ¢
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        original_filename: åŸå§‹æ–‡ä»¶å
        
    Returns:
        è½¬æ¢åçš„markdownå†…å®¹
    """
    try:
        logger.info(f"è°ƒç”¨OCRæœåŠ¡: {original_filename} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
        
        # è°ƒç”¨OCR API
        timeout = httpx.Timeout(180.0, connect=30.0)  # å¢åŠ è¶…æ—¶æ—¶é—´ï¼ŒCPUæ¨¡å¼å¯èƒ½è¾ƒæ…¢
        
        async with httpx.AsyncClient(timeout=timeout) as client:
            # OCRæœåŠ¡çš„APIç«¯ç‚¹ (ä¼˜å…ˆä½¿ç”¨æˆ‘ä»¬çš„æ ‡å‡†OCRæ¥å£)
            api_endpoints = [
                f"{OCR_BASE_URL}/ocr/upload",  # ä¼˜å…ˆä½¿ç”¨æ ‡å‡†OCRä¸Šä¼ ç«¯ç‚¹
                f"{OCR_BASE_URL}/extract"      # å¤‡ç”¨å…¼å®¹DocExtæ ¼å¼çš„ç«¯ç‚¹
            ]
            
            last_error = None
            
            for endpoint in api_endpoints:
                try:
                    logger.info(f"å°è¯•è°ƒç”¨ç«¯ç‚¹: {endpoint} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                    
                    # ä½¿ç”¨æ ‡å‡†çš„FastAPIæ–‡ä»¶ä¸Šä¼ æ ¼å¼
                    with open(file_path, 'rb') as f:
                        files = {'file': (original_filename, f, 'image/*')}
                        data = {
                            'max_new_tokens': '4096',  # å¢åŠ ç”Ÿæˆé•¿åº¦ï¼Œç¡®ä¿èƒ½è¯†åˆ«é•¿æ–‡æœ¬
                            'extract_type': 'ocr'  # å…¼å®¹å‚æ•°
                        }
                        
                        response = await client.post(
                            endpoint,
                            files=files,
                            data=data
                        )
                    
                    logger.info(f"ç«¯ç‚¹ {endpoint} å“åº”çŠ¶æ€: {response.status_code} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                    
                    if response.status_code == 200:
                        try:
                            result = response.json()
                            logger.info(f"ç«¯ç‚¹ {endpoint} å“åº”æ•°æ®ç±»å‹: {type(result)} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                            
                            # å¤„ç†æˆ‘ä»¬OCRæœåŠ¡çš„æ ‡å‡†å“åº”æ ¼å¼
                            if isinstance(result, dict):
                                if result.get('success') and result.get('text'):
                                    markdown_content = result['text'].strip()
                                    if len(markdown_content) > 10:
                                        logger.info(f"OCRè½¬æ¢æˆåŠŸï¼Œä½¿ç”¨ç«¯ç‚¹: {endpoint}ï¼Œå†…å®¹é•¿åº¦: {len(markdown_content)} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                                        return markdown_content
                                elif result.get('error'):
                                    logger.error(f"OCRæœåŠ¡è¿”å›é”™è¯¯: {result['error']} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                                    last_error = result['error']
                                    continue
                            
                            # å…¼å®¹å…¶ä»–æ ¼å¼çš„å“åº”
                            markdown_content = extract_markdown_from_response(result)
                            if markdown_content and len(markdown_content.strip()) > 10:
                                logger.info(f"OCRè½¬æ¢æˆåŠŸ(å…¼å®¹æ ¼å¼)ï¼Œä½¿ç”¨ç«¯ç‚¹: {endpoint}ï¼Œå†…å®¹é•¿åº¦: {len(markdown_content)} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                                return markdown_content
                            else:
                                logger.warning(f"ç«¯ç‚¹ {endpoint} è¿”å›å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                                continue
                                
                        except Exception as parse_error:
                            # å¦‚æœä¸æ˜¯JSONï¼Œå°è¯•ä½œä¸ºæ–‡æœ¬å¤„ç†
                            text_content = response.text.strip()
                            if text_content and len(text_content) > 10:
                                logger.info(f"OCRè½¬æ¢æˆåŠŸ(æ–‡æœ¬æ ¼å¼)ï¼Œä½¿ç”¨ç«¯ç‚¹: {endpoint} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                                return text_content
                            else:
                                logger.warning(f"ç«¯ç‚¹ {endpoint} è§£æå¤±è´¥: {parse_error} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                                continue
                    
                    elif response.status_code == 404:
                        logger.warning(f"ç«¯ç‚¹ {endpoint} ä¸å­˜åœ¨ (404) - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                        continue
                    
                    elif response.status_code == 422:
                        logger.warning(f"ç«¯ç‚¹ {endpoint} å‚æ•°é”™è¯¯ (422): {response.text} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                        last_error = f"å‚æ•°é”™è¯¯: {response.text}"
                        continue
                    
                    else:
                        logger.warning(f"ç«¯ç‚¹ {endpoint} è¿”å›é”™è¯¯: {response.status_code} - {response.text} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                        last_error = f"HTTP {response.status_code}: {response.text}"
                        continue
                        
                except httpx.ConnectError as e:
                    logger.warning(f"æ— æ³•è¿æ¥åˆ°ç«¯ç‚¹ {endpoint}: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                    last_error = f"è¿æ¥é”™è¯¯: {str(e)}"
                    continue
                    
                except httpx.TimeoutException as e:
                    logger.warning(f"ç«¯ç‚¹ {endpoint} è¶…æ—¶: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                    last_error = f"è¯·æ±‚è¶…æ—¶: {str(e)}"
                    continue
                    
                except Exception as e:
                    logger.warning(f"è°ƒç”¨ç«¯ç‚¹ {endpoint} æ—¶å‡ºé”™: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
                    last_error = str(e)
                    continue
            
            # æ‰€æœ‰ç«¯ç‚¹éƒ½å¤±è´¥äº†
            raise Exception(f"æ‰€æœ‰OCRç«¯ç‚¹éƒ½æ— æ³•è®¿é—®ã€‚OCRæœåŠ¡å¯èƒ½æœªå¯åŠ¨æˆ–é…ç½®é”™è¯¯ã€‚æœ€åçš„é”™è¯¯: {last_error}")
            
    except Exception as e:
        logger.error(f"è°ƒç”¨OCRæœåŠ¡å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: call_ocr_service")
        raise Exception(f"å›¾ç‰‡è½¬æ¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}")

@router.post("/chat-with-documents")
async def chat_with_documents(
    request: Request,
    files: List[UploadFile] = File(...),
    message: str = Form(""),
    history: str = Form("[]")
) -> StreamingResponse:
    """
    æ–‡æ¡£èŠå¤©æ¥å£ - å¤„ç†æ–‡æ¡£å’Œæ¶ˆæ¯çš„ç»„åˆè¯·æ±‚
    æ”¯æŒå¤šæ–‡æ¡£ä¸Šä¼ ï¼Œå¹¶åŸºäºæ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜
    
    Args:
        request: FastAPIè¯·æ±‚å¯¹è±¡
        files: ä¸Šä¼ çš„æ–‡æ¡£æ–‡ä»¶åˆ—è¡¨
        message: ç”¨æˆ·é—®é¢˜
        history: èŠå¤©å†å²è®°å½•ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
        
    Returns:
        æµå¼èŠå¤©å“åº”
    """
    try:
        start_time = time.time()
        logger.info(f"å¼€å§‹å¤„ç†æ–‡æ¡£èŠå¤©è¯·æ±‚ï¼Œæ–‡ä»¶æ•°é‡: {len(files)}, æ¶ˆæ¯: {message[:100]}... - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
        
        # è§£æå†å²è®°å½•
        try:
            chat_history = json.loads(history) if history else []
        except json.JSONDecodeError:
            chat_history = []
        
        # å¤„ç†æ‰€æœ‰æ–‡æ¡£
        all_document_contents = []
        document_summaries = []
        
        for file in files:
            # æ£€æŸ¥æ–‡ä»¶
            if not file.filename:
                continue
                
            if not is_supported_file(file.filename):
                logger.warning(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶: {file.filename} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
                continue
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = await file.read()
            if len(content) > MAX_FILE_SIZE:
                logger.warning(f"æ–‡ä»¶è¿‡å¤§ï¼Œè·³è¿‡: {file.filename} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
                continue
            
            file_type = get_file_type(file.filename)
            logger.info(f"å¤„ç†æ–‡ä»¶: {file.filename}, ç±»å‹: {file_type} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
            if file_type == "image":
                # å›¾ç‰‡æ–‡ä»¶ - ä½¿ç”¨OCR
                try:
                    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                    unique_filename = generate_unique_filename(file.filename)
                    temp_file_path = UPLOAD_DIR / unique_filename
                    with open(temp_file_path, "wb") as buffer:
                        buffer.write(content)
                    
                    # è°ƒç”¨OCRæœåŠ¡
                    text_content = await call_ocr_service(temp_file_path, file.filename)
                    all_document_contents.append({
                        "filename": file.filename,
                        "type": "å›¾ç‰‡OCR",
                        "content": text_content
                    })
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if temp_file_path.exists():
                        temp_file_path.unlink()
                        
                except Exception as e:
                    logger.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {file.filename} - {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
                    continue
                    
            elif file_type == "document":
                # æ–‡æ¡£æ–‡ä»¶ - ä½¿ç”¨æ–‡æ¡£å¤„ç†
                try:
                    doc_result = await document_service.process_document(content, file.filename)
                    text_content = doc_result['content']
                    
                    all_document_contents.append({
                        "filename": file.filename,
                        "type": doc_result['file_type'],
                        "content": text_content,
                        "page_count": doc_result.get('page_count', 1)
                    })
                    
                except Exception as e:
                    logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {file.filename} - {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
                    continue
        
        if not all_document_contents:
            # æ²¡æœ‰æˆåŠŸå¤„ç†çš„æ–‡æ¡£
            async def error_generator():
                error_response = {
                    "choices": [{
                        "delta": {
                            "content": "âŒ **æ–‡æ¡£å¤„ç†å¤±è´¥**\n\næŠ±æ­‰ï¼Œæ— æ³•å¤„ç†æ‚¨ä¸Šä¼ çš„æ–‡æ¡£ã€‚è¯·æ£€æŸ¥æ–‡æ¡£æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¨åé‡è¯•ã€‚"
                        }
                    }]
                }
                yield f"data: {json.dumps(error_response)}\n\n"
                yield "data: [DONE]\n\n"
            
            return StreamingResponse(
                error_generator(),
                media_type="text/plain",
                headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
            )
        
        # å¤„ç†æ–‡æ¡£å†…å®¹ - åˆ¤æ–­é•¿åº¦å¹¶è¿›è¡Œæ€»ç»“
        processed_contents = []
        for doc in all_document_contents:
            content = doc['content']
            
            # åˆ¤æ–­å†…å®¹é•¿åº¦
            if len(content) > 2000:  # è¶…è¿‡2kå­—ç¬¦
                logger.info(f"æ–‡æ¡£å†…å®¹è¿‡é•¿({len(content)}å­—ç¬¦)ï¼Œå¼€å§‹æ€»ç»“: {doc['filename']} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
                
                # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ€»ç»“
                try:
                    summary = await summarize_long_document(content, doc['filename'])
                    processed_contents.append({
                        "filename": doc['filename'],
                        "type": doc['type'],
                        "content": summary,
                        "is_summary": True,
                        "original_length": len(content)
                    })
                    logger.info(f"æ–‡æ¡£æ€»ç»“å®Œæˆ: {doc['filename']}, åŸé•¿åº¦: {len(content)}, æ€»ç»“é•¿åº¦: {len(summary)} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
                except Exception as e:
                    logger.error(f"æ–‡æ¡£æ€»ç»“å¤±è´¥: {doc['filename']} - {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
                    # æ€»ç»“å¤±è´¥ï¼Œæˆªå–å‰2000å­—ç¬¦
                    processed_contents.append({
                        "filename": doc['filename'],
                        "type": doc['type'],
                        "content": content[:2000] + "...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–)",
                        "is_summary": False,
                        "original_length": len(content)
                    })
            else:
                # å†…å®¹ä¸é•¿ï¼Œç›´æ¥ä½¿ç”¨
                processed_contents.append({
                    "filename": doc['filename'],
                    "type": doc['type'],
                    "content": content,
                    "is_summary": False,
                    "original_length": len(content)
                })
        
        # æ„å»ºæç¤ºè¯
        prompt = build_document_chat_prompt(processed_contents, message, chat_history)
        
        # è°ƒç”¨èŠå¤©API
        from config import settings
        
        async def stream_generator():
            try:
                # å¯¼å…¥èŠå¤©ç›¸å…³æ¨¡å—
                from api.agents.base import ATMPAgent
                
                # åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹
                agent = ATMPAgent()
                
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                messages = []
                
                # æ·»åŠ ç³»ç»Ÿæç¤º
                messages.append({
                    "role": "system",
                    "content": prompt
                })
                
                # æ·»åŠ å†å²è®°å½•
                for hist_msg in chat_history[-4:]:  # åªä¿ç•™æœ€è¿‘4æ¡å†å²è®°å½•
                    messages.append(hist_msg)
                
                # æ·»åŠ å½“å‰é—®é¢˜
                if message:
                    messages.append({
                        "role": "user", 
                        "content": message
                    })
                
                # æµå¼ç”Ÿæˆå›ç­”
                async for chunk in agent.get_streaming_answer(message, messages):
                    if chunk and hasattr(chunk, 'content') and chunk.content:
                        response_data = {
                            "choices": [{
                                "delta": {
                                    "content": chunk.content
                                }
                            }]
                        }
                        yield f"data: {json.dumps(response_data)}\n\n"
                
                # å‘é€ç»“æŸæ ‡å¿—
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                logger.error(f"æµå¼ç”Ÿæˆå¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: stream_generator")
                error_response = {
                    "choices": [{
                        "delta": {
                            "content": f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
                        }
                    }]
                }
                yield f"data: {json.dumps(error_response)}\n\n"
                yield "data: [DONE]\n\n"
        
        logger.info(f"æ–‡æ¡£èŠå¤©å¤„ç†å®Œæˆï¼Œç”¨æ—¶: {time.time() - start_time:.2f}ç§’ - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
        
        return StreamingResponse(
            stream_generator(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
        )
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£èŠå¤©è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: chat_with_documents")
        
        async def error_generator():
            error_response = {
                "choices": [{
                    "delta": {
                        "content": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†é”™è¯¯ï¼š{str(e)}"
                    }
                }]
            }
            yield f"data: {json.dumps(error_response)}\n\n"
            yield "data: [DONE]\n\n"
        
        return StreamingResponse(
            error_generator(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
        )

async def summarize_long_document(content: str, filename: str) -> str:
    """
    å¯¹é•¿æ–‡æ¡£è¿›è¡Œæ€»ç»“
    
    Args:
        content: æ–‡æ¡£å†…å®¹
        filename: æ–‡ä»¶å
        
    Returns:
        æ€»ç»“åçš„å†…å®¹
    """
    try:
        from langchain_openai import ChatOpenAI
        from config import settings
        
        # ä½¿ç”¨è½»é‡çº§æ¨¡å‹è¿›è¡Œæ€»ç»“
        summarizer = ChatOpenAI(
            model=settings.MODELNAME,
            api_key=settings.OPENAI_API_KEY,
            base_url=settings.OPENAI_BASE_URL,
            temperature=0.3
        )
        
        # æ„å»ºæ€»ç»“æç¤ºè¯
        summarize_prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æ¡£å†…å®¹è¿›è¡Œæ€»ç»“å’Œæç‚¼ï¼Œä¿ç•™å…³é”®ä¿¡æ¯å’Œè¦ç‚¹ï¼š

æ–‡æ¡£åç§°ï¼š{filename}
æ–‡æ¡£å†…å®¹ï¼š
{content}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ€»ç»“ï¼š

## ğŸ“‹ æ–‡æ¡£æ€»ç»“

### ğŸ¯ æ ¸å¿ƒè¦ç‚¹
[åˆ—å‡º3-5ä¸ªæ ¸å¿ƒè¦ç‚¹]

### ğŸ“Š å…³é”®ä¿¡æ¯
[æå–é‡è¦çš„æ•°æ®ã€ç»“è®ºã€å»ºè®®ç­‰]

### ğŸ” è¯¦ç»†å†…å®¹
[ä¿ç•™é‡è¦çš„ç»†èŠ‚ä¿¡æ¯ï¼Œä½†è¦ç®€æ´æ˜äº†]

è¦æ±‚ï¼š
1. ä¿ç•™æ‰€æœ‰é‡è¦çš„åŒ»ç–—è¯„ä»·ç›¸å…³ä¿¡æ¯
2. çªå‡ºå…³é”®æ•°æ®å’Œç»“è®º
3. ä¿æŒé€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´
4. æ€»ç»“é•¿åº¦æ§åˆ¶åœ¨1500å­—ä»¥å†…
"""
        
        # è°ƒç”¨æ¨¡å‹è¿›è¡Œæ€»ç»“
        response = await summarizer.ainvoke(summarize_prompt)
        summary = response.content.strip()
        
        return summary
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£æ€»ç»“å¤±è´¥: {filename} - {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: summarize_long_document")
        # æ€»ç»“å¤±è´¥ï¼Œè¿”å›æˆªå–çš„å†…å®¹
        return content[:1500] + "\n\n...(åŸæ–‡æ¡£å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å…³é”®éƒ¨åˆ†)"

def build_document_chat_prompt(documents: List[Dict], user_message: str, chat_history: List[Dict]) -> str:
    """
    æ„å»ºæ–‡æ¡£èŠå¤©çš„æç¤ºè¯
    
    Args:
        documents: å¤„ç†åçš„æ–‡æ¡£å†…å®¹åˆ—è¡¨
        user_message: ç”¨æˆ·é—®é¢˜
        chat_history: èŠå¤©å†å²
        
    Returns:
        æ„å»ºçš„æç¤ºè¯
    """
    # æ„å»ºæ–‡æ¡£å†…å®¹éƒ¨åˆ†
    docs_content = ""
    for i, doc in enumerate(documents, 1):
        summary_note = " (å·²æ€»ç»“)" if doc.get('is_summary') else ""
        docs_content += f"""
## ğŸ“„ æ–‡æ¡£ {i}: {doc['filename']} ({doc['type']}{summary_note})

{doc['content']}

---
"""
    
    # æ„å»ºå®Œæ•´æç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—è¯„ä»·åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æåŒ»ç–—é¡¹ç›®ã€ä¸´åºŠè¯•éªŒã€è¯ç‰©è¯„ä¼°ç­‰ç›¸å…³æ–‡æ¡£ã€‚

## ğŸ“š å‚è€ƒæ–‡æ¡£
ç”¨æˆ·å·²ä¸Šä¼ äº†ä»¥ä¸‹æ–‡æ¡£ï¼Œè¯·åŸºäºè¿™äº›æ–‡æ¡£å†…å®¹æ¥å›ç­”é—®é¢˜ï¼š

{docs_content}

## ğŸ¯ ä»»åŠ¡è¦æ±‚
1. **åŸºäºæ–‡æ¡£å†…å®¹å›ç­”**ï¼šä¸»è¦å‚è€ƒä¸Šè¿°æ–‡æ¡£å†…å®¹æ¥å›ç­”ç”¨æˆ·é—®é¢˜
2. **ä¸“ä¸šæ€§**ï¼šä½¿ç”¨ä¸“ä¸šçš„åŒ»ç–—è¯„ä»·æœ¯è¯­å’Œæ ‡å‡†
3. **å‡†ç¡®æ€§**ï¼šç¡®ä¿å›ç­”å‡†ç¡®ï¼Œé¿å…è¿‡åº¦è§£è¯»æˆ–æ¨æµ‹
4. **ç»“æ„åŒ–**ï¼šä½¿ç”¨æ¸…æ™°çš„æ ¼å¼ç»„ç»‡å›ç­”ï¼Œä¾¿äºé˜…è¯»
5. **å¼•ç”¨è¯´æ˜**ï¼šåœ¨å›ç­”ä¸­é€‚å½“å¼•ç”¨å…·ä½“çš„æ–‡æ¡£å†…å®¹

## ğŸ’¡ å›ç­”æ ¼å¼å»ºè®®
- ä½¿ç”¨æ ‡é¢˜å’Œå­æ ‡é¢˜ç»„ç»‡å†…å®¹
- é‡è¦ä¿¡æ¯ç”¨**ç²—ä½“**æ ‡è®°
- ä½¿ç”¨åˆ—è¡¨å±•ç¤ºè¦ç‚¹
- å¿…è¦æ—¶æä¾›è¡¨æ ¼æˆ–å›¾è¡¨è¯´æ˜
- åœ¨å›ç­”æœ«å°¾æ³¨æ˜å‚è€ƒçš„æ–‡æ¡£

è¯·åŸºäºä»¥ä¸Šæ–‡æ¡£å†…å®¹ï¼Œä¸“ä¸šã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœé—®é¢˜è¶…å‡ºæ–‡æ¡£èŒƒå›´ï¼Œè¯·æ˜ç¡®è¯´æ˜å¹¶æä¾›ä¸€èˆ¬æ€§çš„ä¸“ä¸šå»ºè®®ã€‚"""

    return prompt

def extract_markdown_from_response(response_data) -> str:
    """ä»DocExtå“åº”ä¸­æå–markdownå†…å®¹
    
    Args:
        response_data: DocExt APIå“åº”æ•°æ®
        
    Returns:
        æå–çš„markdownå†…å®¹
    """
    try:
        logger.info(f"å¤„ç†å“åº”æ•°æ®ï¼Œç±»å‹: {type(response_data)} - æ–‡ä»¶: {__file__} - å‡½æ•°: extract_markdown_from_response")
        
        # å¦‚æœç›´æ¥æ˜¯å­—ç¬¦ä¸²ï¼Œè¿”å›
        if isinstance(response_data, str):
            return response_data.strip()
        
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼ˆGradio APIé€šå¸¸è¿”å›åˆ—è¡¨ï¼‰
        if isinstance(response_data, list):
            for item in response_data:
                if isinstance(item, str) and len(item.strip()) > 10:
                    return item.strip()
                elif isinstance(item, dict):
                    nested_result = extract_markdown_from_response(item)
                    if nested_result and len(nested_result.strip()) > 10:
                        return nested_result
        
        # å¦‚æœæ˜¯å­—å…¸
        if isinstance(response_data, dict):
            # Gradio APIå¸¸è§çš„å“åº”æ ¼å¼
            gradio_keys = [
                'data',      # Gradioæ ‡å‡†å“åº”æ ¼å¼
                'prediction', # é¢„æµ‹ç»“æœ
                'output',    # è¾“å‡ºç»“æœ
                'result'     # ç»“æœ
            ]
            
            # é¦–å…ˆå°è¯•Gradioæ ‡å‡†æ ¼å¼
            for key in gradio_keys:
                if key in response_data:
                    value = response_data[key]
                    if isinstance(value, list) and value:
                        # é€šå¸¸Gradioçš„dataæ˜¯ä¸€ä¸ªåˆ—è¡¨
                        nested_result = extract_markdown_from_response(value)
                        if nested_result and len(nested_result.strip()) > 10:
                            return nested_result
                    elif isinstance(value, str) and len(value.strip()) > 10:
                        return value.strip()
            
            # ç„¶åå°è¯•å…¶ä»–å¯èƒ½çš„é”®å
            other_keys = [
                'markdown',
                'content', 
                'text',
                'extracted_text',
                'markdown_content',
                'ocr_result',
                'document_text'
            ]
            
            for key in other_keys:
                if key in response_data and response_data[key]:
                    content = response_data[key]
                    if isinstance(content, str) and len(content.strip()) > 10:
                        return content.strip()
                    elif isinstance(content, list):
                        nested_result = extract_markdown_from_response(content)
                        if nested_result and len(nested_result.strip()) > 10:
                            return nested_result
            
            # æ·±å±‚é€’å½’æŸ¥æ‰¾
            for key, value in response_data.items():
                if isinstance(value, (dict, list)):
                    nested_result = extract_markdown_from_response(value)
                    if nested_result and len(nested_result.strip()) > 10:
                        return nested_result
                elif isinstance(value, str) and len(value.strip()) > 50:  # å‡è®¾æœ‰æ„ä¹‰çš„å†…å®¹è‡³å°‘50å­—ç¬¦
                    return value.strip()
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›è°ƒè¯•ä¿¡æ¯
        logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå–markdownå†…å®¹ï¼Œå“åº”æ ¼å¼: {list(response_data.keys()) if isinstance(response_data, dict) else type(response_data)} - æ–‡ä»¶: {__file__} - å‡½æ•°: extract_markdown_from_response")
        
        # è¿”å›æ ¼å¼åŒ–çš„è°ƒè¯•ä¿¡æ¯
        if isinstance(response_data, dict):
            return f"å“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸã€‚å“åº”é”®: {list(response_data.keys())}\nå“åº”å†…å®¹: {str(response_data)[:500]}..."
        else:
            return f"å“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸã€‚å“åº”ç±»å‹: {type(response_data)}\nå“åº”å†…å®¹: {str(response_data)[:500]}..."
        
    except Exception as e:
        logger.error(f"æå–markdownå†…å®¹å¤±è´¥: {str(e)} - æ–‡ä»¶: {__file__} - å‡½æ•°: extract_markdown_from_response")
        return f"å†…å®¹æå–å¤±è´¥: {str(e)}" 