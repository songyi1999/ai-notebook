version: '3.8'

name: ai-notebook

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:8000
    depends_on:
      - backend
    networks:
      - ai-notebook-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - APP_NAME=AI笔记本
      - APP_VERSION=1.0.0
      - DEBUG_MODE=false
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8000
      - DATABASE_URL=sqlite:///./data/notebook.db
      - CHROMA_DB_PATH=./data/chroma_db
      - API_URL=http://host.docker.internal:11434 # 指向宿主机上运行的OpenAI兼容服务
      - API_KEY= # 本地模型通常不需要key
      - LLM_MODEL_NAME=llama3.2:latest
      - EMBEDDING_MODEL_NAME=bge-m3:latest
      - LLM_TEMPERATURE=0.7
      - LLM_MAX_TOKENS=2048
      - EMBEDDING_DIMENSION=1024
      - NOTES_ROOT_PATH=./data/notes
      - MAX_FILE_SIZE=10485760
      - SEARCH_CHUNK_SIZE=1000
      - SEARCH_OVERLAP=200
    volumes:
      - ./data:/app/data
      - ./notes:/app/data/notes
    networks:
      - ai-notebook-network

networks:
  ai-notebook-network:
    driver: bridge 