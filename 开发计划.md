要优化AI聊天体验，当用户输入问题意图识别是需要知识库时。
1. 从向量数据库中能匹配到片段，这个片段有可能是 文章内容片段，总结，或提纲。
若是提取片段的时候，通过片段的文章id 的 查找到文件总结和文章提纲，一并返回给用户。
若是提取到的是总结或提纲，则通过文章id 的 查找到文件的总结和提纲，返回给用户。
此功能能丰富LLM 的参考信息，让LLM 的回答更准确。
2. LLM回复用户后，在服务端需用变量获取回复的内容并进一步思考是否已经完全回答了用户的问题。若未能完全回复，则可自行决定进行知识搜索或工具调用，来进一步回答用户问题。可能需要一个工具调用，来实现这个功能。

3. 实现上述功能时，需同时考虑优化前端的体验，不要让用户一直等待，比如一个回复后未能完全回答用户问题时，可以继续输出思考情况，例如：“我需要进一步仔细回答用户的问题，考虑到什么什么情况，我需要执行什么什么 搜索，或调用什么什么工具” ，然后进行下一轮输出。
