# 应用配置
APP_NAME=AI笔记本
APP_VERSION=1.0.0
DEBUG_MODE=false

# 服务器配置
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# 数据存储配置 - 统一存储在backend/data目录
DATABASE_URL=sqlite:///./data/ai_notebook.db
CHROMA_DB_PATH=./data/chroma_db
DATA_DIRECTORY=./data

# OpenAI兼容API配置
# 本地AI服务(如Ollama, LMStudio)的OpenAI兼容API地址
# 在Docker外本地运行后端时，使用localhost
# 在Docker容器内运行后端时，应在docker-compose.yml中设置为 http://host.docker.internal:端口
OPENAI_BASE_URL=http://localhost:11434

# API密钥 (如果您的服务需要)
OPENAI_API_KEY=

# 您在本地AI服务中加载的语言模型名称
OPENAI_MODEL=llama3.1:8b

# AI模型参数
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2048
EMBEDDING_DIMENSION=1024

# 文件存储配置
NOTES_DIRECTORY=../notes  # 相对于backend目录，指向项目根目录的notes
MAX_FILE_SIZE=10485760

# 搜索配置
SEARCH_LIMIT=50
SEARCH_CHUNK_SIZE=1000
SEARCH_OVERLAP=200

# API配置
API_PREFIX=/api/v1
LOG_LEVEL=INFO

# 前端配置
REACT_APP_API_BASE_URL=http://localhost:8000 